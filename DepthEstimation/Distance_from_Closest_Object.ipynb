{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShudarshanKongkham/AgenticDrone_Basic/blob/main/Distance_from_Closest_Object.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Distance Calculation from Closest Object using Depth Estimation\n",
        "\n",
        "This notebook demonstrates how to calculate the distance to the closest object in a scene using monocular depth estimation. This is particularly useful for obstacle avoidance in robotics, drone navigation, and safety applications.\n",
        "\n",
        "<div style=\"text-align: center;\">\n",
        "  <figure style=\"display: inline-block;\">\n",
        "    <img src=\"https://learnopencv.com/wp-content/uploads/2024/02/animal-depth-anything-large.gif\" alt=\"Distance Calculation from Closest Object\" width = 900>\n",
        "    <figcaption style=\"text-align: center;\">Distance Calculation from Closest Object using Depth Estimation</figcaption>\n",
        "  </figure>\n",
        "</div>\n",
        "\n",
        "## Key Features:\n",
        "- Real-time depth estimation using DepthPro\n",
        "- Distance calculation to the closest object\n",
        "- Visual highlighting of the closest object region\n",
        "- Interactive interface for testing with different images\n",
        "- Conversion from depth values to real-world distances\n",
        "- Safety zone visualization for obstacle avoidance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "## 1. Setup and Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture\n",
        "!git clone https://github.com/apple/ml-depth-pro.git\n",
        "%cd ml-depth-pro\n",
        "!pip install -e .\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download the model checkpoint from huggingface\n",
        "%%capture\n",
        "!pip install huggingface-hub\n",
        "!pip install gradio\n",
        "!huggingface-cli download --local-dir checkpoints apple/DepthPro\n",
        "%cd ..\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# To avoid depth pro import errors\n",
        "!pip install numpy==1.26.4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "üìå **Restart Session** after installing dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Tuple, Dict\n",
        "import time\n",
        "import torch\n",
        "import gradio as gr\n",
        "from scipy import ndimage\n",
        "\n",
        "# Add the src path for depth_pro\n",
        "sys.path.append('ml-depth-pro/src')\n",
        "!ln -s ml-depth-pro/checkpoints ./checkpoints # create a symbolic link to manage relative paths\n",
        "\n",
        "os.makedirs(\"input_images\", exist_ok=True)\n",
        "os.makedirs(\"distance_results\", exist_ok=True)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import depth_pro\n",
        "\n",
        "# Load model and preprocessing transform\n",
        "model, transform = depth_pro.create_model_and_transforms(precision=torch.half)\n",
        "model.to(\"cuda\").eval()\n",
        "print(\"DepthPro Model Loaded Successfully...‚úÖ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 2. Core Distance Calculation Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_depth_with_distance(rgb_image: np.ndarray) -> Tuple[np.ndarray, float, Dict]:\n",
        "    \"\"\"\n",
        "    Predict depth map and calculate distance to closest object\n",
        "    \n",
        "    Args:\n",
        "        rgb_image: Input RGB image\n",
        "        \n",
        "    Returns:\n",
        "        depth_map: Normalized depth map for visualization\n",
        "        min_distance: Distance to closest object in meters\n",
        "        stats: Dictionary with depth statistics\n",
        "    \"\"\"\n",
        "    # Prepare image for model\n",
        "    image = transform(rgb_image).to(\"cuda\")\n",
        "    \n",
        "    # Get depth prediction\n",
        "    with torch.no_grad():\n",
        "        prediction = model.infer(image)\n",
        "        depth = prediction[\"depth\"].detach().cpu().numpy().squeeze()\n",
        "    \n",
        "    # Calculate distance statistics\n",
        "    min_distance = float(depth.min())\n",
        "    max_distance = float(depth.max())\n",
        "    mean_distance = float(depth.mean())\n",
        "    \n",
        "    # Create normalized depth map for visualization\n",
        "    depth_normalized = cv2.normalize(depth, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
        "    \n",
        "    stats = {\n",
        "        'min_distance': min_distance,\n",
        "        'max_distance': max_distance,\n",
        "        'mean_distance': mean_distance,\n",
        "        'closest_object_pixels': np.sum(depth == depth.min())\n",
        "    }\n",
        "    \n",
        "    return depth_normalized, min_distance, stats, depth\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_closest_object_region(depth_map: np.ndarray, tolerance: float = 0.1) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Find and highlight the region containing the closest object\n",
        "    \n",
        "    Args:\n",
        "        depth_map: Raw depth map from model\n",
        "        tolerance: Distance tolerance for grouping closest pixels\n",
        "        \n",
        "    Returns:\n",
        "        mask: Binary mask highlighting closest object region\n",
        "    \"\"\"\n",
        "    min_depth = depth_map.min()\n",
        "    \n",
        "    # Create mask for pixels within tolerance of minimum depth\n",
        "    closest_mask = depth_map <= (min_depth + tolerance)\n",
        "    \n",
        "    # Apply morphological operations to clean up the mask\n",
        "    kernel = np.ones((5, 5), np.uint8)\n",
        "    closest_mask = cv2.morphologyEx(closest_mask.astype(np.uint8), cv2.MORPH_CLOSE, kernel)\n",
        "    closest_mask = cv2.morphologyEx(closest_mask, cv2.MORPH_OPEN, kernel)\n",
        "    \n",
        "    return closest_mask.astype(bool)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_distance_visualization(rgb_image: np.ndarray, depth_map: np.ndarray, \n",
        "                                min_distance: float, closest_mask: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Create a visualization showing the closest object highlighted\n",
        "    \n",
        "    Args:\n",
        "        rgb_image: Original RGB image\n",
        "        depth_map: Normalized depth map\n",
        "        min_distance: Distance to closest object\n",
        "        closest_mask: Mask highlighting closest object\n",
        "        \n",
        "    Returns:\n",
        "        visualization: Combined visualization image\n",
        "    \"\"\"\n",
        "    h, w = rgb_image.shape[:2]\n",
        "    \n",
        "    # Create overlay for closest object\n",
        "    overlay = rgb_image.copy()\n",
        "    overlay[closest_mask] = [0, 255, 0]  # Highlight in green\n",
        "    \n",
        "    # Blend with original image\n",
        "    result = cv2.addWeighted(rgb_image, 0.7, overlay, 0.3, 0)\n",
        "    \n",
        "    # Add distance text\n",
        "    text = f\"Closest Object: {min_distance:.2f}m\"\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    font_scale = 0.8\n",
        "    thickness = 2\n",
        "    \n",
        "    # Get text size for background rectangle\n",
        "    (text_width, text_height), _ = cv2.getTextSize(text, font, font_scale, thickness)\n",
        "    \n",
        "    # Draw background rectangle\n",
        "    cv2.rectangle(result, (10, 10), (text_width + 20, text_height + 20), (0, 0, 0), -1)\n",
        "    \n",
        "    # Draw text\n",
        "    cv2.putText(result, text, (15, text_height + 15), font, font_scale, (255, 255, 255), thickness)\n",
        "    \n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 3. Complete Processing Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_image_for_distance(rgb_image: np.ndarray) -> Tuple[np.ndarray, np.ndarray, str]:\n",
        "    \"\"\"\n",
        "    Complete pipeline for distance calculation and visualization\n",
        "    \n",
        "    Args:\n",
        "        rgb_image: Input RGB image\n",
        "        \n",
        "    Returns:\n",
        "        depth_vis: Depth map visualization\n",
        "        distance_vis: Distance visualization with highlighted closest object\n",
        "        stats_text: Formatted statistics text\n",
        "    \"\"\"\n",
        "    # Get depth prediction and distance calculation\n",
        "    depth_normalized, min_distance, stats, raw_depth = predict_depth_with_distance(rgb_image)\n",
        "    \n",
        "    # Find closest object region\n",
        "    closest_mask = find_closest_object_region(raw_depth)\n",
        "    \n",
        "    # Create visualizations\n",
        "    distance_vis = create_distance_visualization(rgb_image, depth_normalized, min_distance, closest_mask)\n",
        "    \n",
        "    # Create depth visualization with colormap\n",
        "    depth_colored = cv2.applyColorMap(depth_normalized, cv2.COLORMAP_PLASMA)\n",
        "    \n",
        "    # Format statistics\n",
        "    stats_text = f\"\"\"\n",
        "üìè Distance Statistics:\n",
        "‚Ä¢ Closest Object: {stats['min_distance']:.2f} meters\n",
        "‚Ä¢ Farthest Object: {stats['max_distance']:.2f} meters\n",
        "‚Ä¢ Average Distance: {stats['mean_distance']:.2f} meters\n",
        "‚Ä¢ Closest Object Area: {stats['closest_object_pixels']} pixels\n",
        "    \"\"\"\n",
        "    \n",
        "    return depth_colored, distance_vis, stats_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 4. Download Test Images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download test images\n",
        "!wget https://learnopencv.com/wp-content/uploads/2025/04/Leopard-Cub.jpeg -O input_images/leopard.jpeg\n",
        "!wget https://learnopencv.com/wp-content/uploads/2025/04/cave-scaled.jpg -O input_images/cave.jpg\n",
        "!wget https://images.unsplash.com/photo-1506905925346-21bda4d32df4 -O input_images/mountain_road.jpg\n",
        "!wget https://images.unsplash.com/photo-1551218808-94e220e084d2 -O input_images/office.jpg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 5. Interactive Gradio Interface\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Global variables for storing processed data\n",
        "stored_rgb = None\n",
        "stored_depth = None\n",
        "stored_stats = None\n",
        "\n",
        "def analyze_distance(rgb_image):\n",
        "    \"\"\"Process image and return distance analysis\"\"\"\n",
        "    global stored_rgb, stored_depth, stored_stats\n",
        "    \n",
        "    stored_rgb = rgb_image\n",
        "    depth_vis, distance_vis, stats_text = process_image_for_distance(rgb_image)\n",
        "    \n",
        "    return depth_vis, distance_vis, stats_text\n",
        "\n",
        "def update_tolerance(tolerance):\n",
        "    \"\"\"Update visualization with new tolerance value\"\"\"\n",
        "    global stored_rgb\n",
        "    \n",
        "    if stored_rgb is not None:\n",
        "        # Reprocess with new tolerance\n",
        "        depth_normalized, min_distance, stats, raw_depth = predict_depth_with_distance(stored_rgb)\n",
        "        closest_mask = find_closest_object_region(raw_depth, tolerance=tolerance)\n",
        "        distance_vis = create_distance_visualization(stored_rgb, depth_normalized, min_distance, closest_mask)\n",
        "        \n",
        "        return distance_vis\n",
        "    \n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create Gradio interface\n",
        "with gr.Blocks(title=\"Distance from Closest Object\") as demo:\n",
        "    gr.Markdown(\"\"\"\n",
        "    # üéØ Distance Calculation from Closest Object\n",
        "    \n",
        "    Upload an image to analyze the distance to the closest object using monocular depth estimation.\n",
        "    The closest object will be highlighted in green, and distance statistics will be displayed.\n",
        "    \"\"\")\n",
        "    \n",
        "    with gr.Tab(\"üì∏ Distance Analysis\"):\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                image_input = gr.Image(type=\"numpy\", label=\"Upload Image\")\n",
        "                analyze_btn = gr.Button(\"üîç Analyze Distance\", variant=\"primary\")\n",
        "                \n",
        "                gr.Markdown(\"### üéõÔ∏è Adjustment Controls\")\n",
        "                tolerance_slider = gr.Slider(\n",
        "                    minimum=0.01, \n",
        "                    maximum=1.0, \n",
        "                    value=0.1, \n",
        "                    step=0.01,\n",
        "                    label=\"Object Detection Tolerance (meters)\",\n",
        "                    info=\"Adjust how strictly to define the 'closest object'\"\n",
        "                )\n",
        "            \n",
        "            with gr.Column():\n",
        "                depth_output = gr.Image(label=\"üåà Depth Map Visualization\")\n",
        "                distance_output = gr.Image(label=\"üéØ Distance Analysis (Closest Object Highlighted)\")\n",
        "        \n",
        "        with gr.Row():\n",
        "            stats_output = gr.Textbox(\n",
        "                label=\"üìä Distance Statistics\", \n",
        "                lines=6,\n",
        "                interactive=False\n",
        "            )\n",
        "    \n",
        "    with gr.Tab(\"‚ÑπÔ∏è About\"):\n",
        "        gr.Markdown(\"\"\"\n",
        "        ## How it works:\n",
        "        \n",
        "        1. **Depth Estimation**: Uses Apple's DepthPro model for monocular depth estimation\n",
        "        2. **Distance Calculation**: Finds the minimum depth value to identify the closest object\n",
        "        3. **Object Highlighting**: Creates a mask to highlight the region of the closest object\n",
        "        4. **Visualization**: Overlays the results on the original image with distance information\n",
        "        \n",
        "        ## Applications:\n",
        "        - üöÅ Drone obstacle avoidance\n",
        "        - ü§ñ Robot navigation\n",
        "        - üöó Autonomous vehicle safety\n",
        "        - üì± AR/VR applications\n",
        "        - üéÆ Gaming and simulation\n",
        "        \n",
        "        ## Tips:\n",
        "        - **Tolerance**: Lower values = stricter definition of \"closest object\"\n",
        "        - **Lighting**: Better lighting conditions improve depth estimation accuracy\n",
        "        - **Scene Complexity**: Simple scenes with clear objects work best\n",
        "        \"\"\")\n",
        "    \n",
        "    # Event handlers\n",
        "    analyze_btn.click(\n",
        "        fn=analyze_distance,\n",
        "        inputs=image_input,\n",
        "        outputs=[depth_output, distance_output, stats_output]\n",
        "    )\n",
        "    \n",
        "    tolerance_slider.change(\n",
        "        fn=update_tolerance,\n",
        "        inputs=tolerance_slider,\n",
        "        outputs=distance_output\n",
        "    )\n",
        "\n",
        "# Launch the interface\n",
        "demo.launch(debug=True, share=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 6. Advanced Features and Safety Zones\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_distance_heatmap(depth_map: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Create a distance heatmap visualization\n",
        "    \n",
        "    Args:\n",
        "        depth_map: Raw depth map from model\n",
        "        \n",
        "    Returns:\n",
        "        heatmap: Color-coded distance heatmap\n",
        "    \"\"\"\n",
        "    # Normalize depth for visualization\n",
        "    depth_norm = cv2.normalize(depth_map, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
        "    \n",
        "    # Apply color map (closer = red, farther = blue)\n",
        "    heatmap = cv2.applyColorMap(255 - depth_norm, cv2.COLORMAP_JET)\n",
        "    \n",
        "    return heatmap\n",
        "\n",
        "def calculate_safety_zones(depth_map: np.ndarray, warning_distance: float = 2.0, \n",
        "                          danger_distance: float = 1.0) -> Tuple[np.ndarray, Dict]:\n",
        "    \"\"\"\n",
        "    Calculate safety zones based on distance thresholds\n",
        "    \n",
        "    Args:\n",
        "        depth_map: Raw depth map\n",
        "        warning_distance: Distance threshold for warning zone (meters)\n",
        "        danger_distance: Distance threshold for danger zone (meters)\n",
        "        \n",
        "    Returns:\n",
        "        safety_mask: Color-coded safety zones\n",
        "        zone_stats: Statistics for each safety zone\n",
        "    \"\"\"\n",
        "    h, w = depth_map.shape\n",
        "    safety_mask = np.zeros((h, w, 3), dtype=np.uint8)\n",
        "    \n",
        "    # Define zones\n",
        "    danger_zone = depth_map < danger_distance\n",
        "    warning_zone = (depth_map >= danger_distance) & (depth_map < warning_distance)\n",
        "    safe_zone = depth_map >= warning_distance\n",
        "    \n",
        "    # Color code zones\n",
        "    safety_mask[danger_zone] = [0, 0, 255]    # Red - Danger\n",
        "    safety_mask[warning_zone] = [0, 255, 255] # Yellow - Warning\n",
        "    safety_mask[safe_zone] = [0, 255, 0]      # Green - Safe\n",
        "    \n",
        "    # Calculate statistics\n",
        "    zone_stats = {\n",
        "        'danger_pixels': np.sum(danger_zone),\n",
        "        'warning_pixels': np.sum(warning_zone),\n",
        "        'safe_pixels': np.sum(safe_zone),\n",
        "        'danger_percentage': (np.sum(danger_zone) / (h * w)) * 100,\n",
        "        'warning_percentage': (np.sum(warning_zone) / (h * w)) * 100,\n",
        "        'safe_percentage': (np.sum(safe_zone) / (h * w)) * 100\n",
        "    }\n",
        "    \n",
        "    return safety_mask, zone_stats\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 7. OpenCV Real-time Implementation (for Local Use)\n",
        "\n",
        "For real-time applications like drone navigation or robotics, you can use this OpenCV implementation. \n",
        "**Note**: This code is designed to run locally with a webcam.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment and run this code locally for real-time distance calculation with webcam\n",
        "\n",
        "# import cv2\n",
        "# import numpy as np\n",
        "# import time\n",
        "\n",
        "# def real_time_distance_detection():\n",
        "#     \"\"\"\n",
        "#     Real-time distance detection using webcam\n",
        "#     Press 'q' to quit, 's' to save current frame, 'h' for heatmap mode\n",
        "#     \"\"\"\n",
        "#     cap = cv2.VideoCapture(0)  # Use webcam\n",
        "#     \n",
        "#     if not cap.isOpened():\n",
        "#         print(\"Error: Could not open webcam\")\n",
        "#         return\n",
        "#     \n",
        "#     print(\"Starting real-time distance detection...\")\n",
        "#     print(\"Press 'q' to quit, 's' to save current frame, 'h' to toggle heatmap\")\n",
        "#     \n",
        "#     frame_count = 0\n",
        "#     heatmap_mode = False\n",
        "#     \n",
        "#     while True:\n",
        "#         ret, frame = cap.read()\n",
        "#         if not ret:\n",
        "#             break\n",
        "#         \n",
        "#         # Process every 5th frame to maintain reasonable speed\n",
        "#         if frame_count % 5 == 0:\n",
        "#             try:\n",
        "#                 # Resize frame for faster processing\n",
        "#                 small_frame = cv2.resize(frame, (640, 480))\n",
        "#                 \n",
        "#                 # Convert BGR to RGB\n",
        "#                 rgb_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)\n",
        "#                 \n",
        "#                 # Get depth prediction\n",
        "#                 depth_normalized, min_distance, stats, raw_depth = predict_depth_with_distance(rgb_frame)\n",
        "#                 \n",
        "#                 if heatmap_mode:\n",
        "#                     # Show distance heatmap\n",
        "#                     heatmap = create_distance_heatmap(raw_depth)\n",
        "#                     display_frame = heatmap\n",
        "#                 else:\n",
        "#                     # Show closest object analysis\n",
        "#                     closest_mask = find_closest_object_region(raw_depth)\n",
        "#                     distance_vis = create_distance_visualization(rgb_frame, depth_normalized, min_distance, closest_mask)\n",
        "#                     display_frame = cv2.cvtColor(distance_vis, cv2.COLOR_RGB2BGR)\n",
        "#                 \n",
        "#                 # Add mode indicator\n",
        "#                 mode_text = \"Heatmap Mode\" if heatmap_mode else \"Distance Mode\"\n",
        "#                 cv2.putText(display_frame, mode_text, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "#                 \n",
        "#                 # Resize back to original frame size\n",
        "#                 display_frame = cv2.resize(display_frame, (frame.shape[1], frame.shape[0]))\n",
        "#                 \n",
        "#                 cv2.imshow('Real-time Distance Detection', display_frame)\n",
        "#                 \n",
        "#             except Exception as e:\n",
        "#                 print(f\"Processing error: {e}\")\n",
        "#                 cv2.imshow('Real-time Distance Detection', frame)\n",
        "#         else:\n",
        "#             cv2.imshow('Real-time Distance Detection', frame)\n",
        "#         \n",
        "#         frame_count += 1\n",
        "#         \n",
        "#         # Handle key presses\n",
        "#         key = cv2.waitKey(1) & 0xFF\n",
        "#         if key == ord('q'):\n",
        "#             break\n",
        "#         elif key == ord('s'):\n",
        "#             # Save current frame\n",
        "#             timestamp = int(time.time())\n",
        "#             filename = f\"distance_results/capture_{timestamp}.jpg\"\n",
        "#             cv2.imwrite(filename, display_frame)\n",
        "#             print(f\"Frame saved as {filename}\")\n",
        "#         elif key == ord('h'):\n",
        "#             # Toggle heatmap mode\n",
        "#             heatmap_mode = not heatmap_mode\n",
        "#             print(f\"Heatmap mode: {'ON' if heatmap_mode else 'OFF'}\")\n",
        "#     \n",
        "#     cap.release()\n",
        "#     cv2.destroyAllWindows()\n",
        "#     print(\"Real-time detection stopped.\")\n",
        "\n",
        "# # Uncomment to run real-time detection\n",
        "# # real_time_distance_detection()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 8. Conclusion and Applications\n",
        "\n",
        "This notebook demonstrates how to calculate distances to the closest object using monocular depth estimation. The applications are vast and particularly valuable for autonomous systems:\n",
        "\n",
        "### üöÅ **Drone Applications**:\n",
        "- **Obstacle Avoidance**: Detect and avoid obstacles in real-time during flight\n",
        "- **Landing Assistance**: Calculate distance to landing surfaces for safe landings\n",
        "- **Navigation Safety**: Maintain safe distances from objects during autonomous flight\n",
        "- **Indoor Navigation**: Navigate through buildings and confined spaces\n",
        "\n",
        "### ü§ñ **Robotics**:\n",
        "- **Mobile Robot Navigation**: Path planning with obstacle awareness\n",
        "- **Manipulation Tasks**: Distance feedback for robotic arms and grippers\n",
        "- **Safety Systems**: Emergency stopping when objects are too close\n",
        "- **Human-Robot Interaction**: Maintain safe distances from humans\n",
        "\n",
        "### üöó **Autonomous Vehicles**:\n",
        "- **Collision Avoidance**: Early warning systems for imminent collisions\n",
        "- **Parking Assistance**: Distance to obstacles while parking\n",
        "- **Lane Keeping**: Distance to lane boundaries and other vehicles\n",
        "- **Emergency Braking**: Automatic braking when obstacles are detected\n",
        "\n",
        "### üì± **AR/VR Applications**:\n",
        "- **Object Interaction**: Distance-based interaction in augmented reality\n",
        "- **Spatial Mapping**: Understanding environment layout for virtual objects\n",
        "- **Virtual Object Placement**: Realistic object positioning based on depth\n",
        "- **Gaming**: Distance-based game mechanics and interactions\n",
        "\n",
        "### üè≠ **Industrial Applications**:\n",
        "- **Quality Control**: Distance measurements in manufacturing\n",
        "- **Safety Monitoring**: Worker safety in industrial environments\n",
        "- **Automated Inspection**: Distance-based quality assessment\n",
        "- **Warehouse Robotics**: Navigation and object manipulation\n",
        "\n",
        "### üéØ **Key Advantages**:\n",
        "- **Single Camera**: Works with just one camera (monocular depth estimation)\n",
        "- **Real-time**: Can process video streams in real-time\n",
        "- **Versatile**: Works in various lighting and environmental conditions\n",
        "- **Cost-effective**: No need for expensive depth sensors like LiDAR\n",
        "- **Portable**: Can run on mobile devices and embedded systems\n",
        "\n",
        "The combination of deep learning-based depth estimation with traditional computer vision techniques provides a powerful tool for spatial understanding and safety applications across multiple domains.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
