{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "id": "W5ulopGmf24G",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShudarshanKongkham/AgenticDrone_Basic/blob/main/Drone_Obstacle_Avoidance_DepthEstimator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "m0gTV00af24K",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# ğŸš Drone Obstacle Avoidance using Hugging Face DepthEstimator\n",
        "\n",
        "This notebook demonstrates how to build a drone obstacle avoidance system using the **DepthEstimator** from Hugging Face Transformers. We'll develop and calibrate functions step-by-step to understand the surrounding environment for safe drone navigation.\n",
        "\n",
        "<div style=\"text-align: center;\">\n",
        "  <figure style=\"display: inline-block;\">\n",
        "    <img src=\"https://github.com/huggingface/transformers/raw/main/docs/source/en/imgs/depth-estimation-output.png\" alt=\"Depth Estimation for Obstacle Avoidance\" width = 900>\n",
        "    <figcaption style=\"text-align: center;\">Depth Estimation for Drone Obstacle Avoidance</figcaption>\n",
        "  </figure>\n",
        "</div>\n",
        "\n",
        "## ğŸ¯ **Objectives:**\n",
        "- Build a step-by-step obstacle avoidance system using Hugging Face transformers\n",
        "- Calibrate depth estimation functions for drone navigation\n",
        "- Create safety zones and navigation recommendations\n",
        "- Develop real-time processing capabilities\n",
        "- Test and validate the system before drone integration\n",
        "\n",
        "## ğŸ”§ **Key Features:**\n",
        "- **Multiple Models**: Test different depth estimation models from Hugging Face\n",
        "- **Obstacle Detection**: Identify and classify obstacles by distance\n",
        "- **Safety Zones**: Create danger/warning/safe navigation zones\n",
        "- **Flight Path Planning**: Suggest safe navigation directions\n",
        "- **Calibration Tools**: Fine-tune parameters for your specific drone setup\n",
        "- **Real-time Processing**: Optimize for live video feed processing\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "zz9ORbgRf24L",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ“¦ Step 1: Install Dependencies and Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQ3-G_TWf24M",
        "outputId": "7f190b4e-e75d-4ce7-de9c-3bfe85c9e173"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.31.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.32.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\n",
            "Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.5)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.12)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.3)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly) (9.1.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "%pip install transformers torch torchvision pillow opencv-python matplotlib numpy gradio plotly\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqvkXdadf24O",
        "outputId": "e593ead0-0915-4ec4-8686-87a5e073f6ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… All dependencies imported successfully!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import warnings\n",
        "from typing import Tuple, Dict, List\n",
        "import time\n",
        "import json\n",
        "\n",
        "# Transformers and models\n",
        "from transformers import pipeline, DPTImageProcessor, DPTForDepthEstimation\n",
        "from transformers import AutoImageProcessor, AutoModelForDepthEstimation\n",
        "\n",
        "# Visualization\n",
        "import gradio as gr\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Create directories\n",
        "import os\n",
        "os.makedirs(\"drone_test_images\", exist_ok=True)\n",
        "os.makedirs(\"obstacle_analysis\", exist_ok=True)\n",
        "os.makedirs(\"calibration_data\", exist_ok=True)\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "print(\"âœ… All dependencies imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "q3bq3oPcf24P",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ¤– Step 2: Initialize Depth Estimation Models\n",
        "\n",
        "We'll test multiple depth estimation models from Hugging Face to find the best one for drone navigation:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0M8sim9Zf24P",
        "outputId": "6f016af1-5559-4bf5-c041-713f9572748c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”§ Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "class DroneDepthEstimator:\n",
        "    \"\"\"\n",
        "    A class to handle multiple depth estimation models for drone obstacle avoidance\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.models = {}\n",
        "        self.current_model = None\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        print(f\"ğŸ”§ Using device: {self.device}\")\n",
        "\n",
        "    def load_model(self, model_name: str, model_id: str):\n",
        "        \"\"\"Load a depth estimation model\"\"\"\n",
        "        try:\n",
        "            print(f\"ğŸ“¥ Loading {model_name}...\")\n",
        "\n",
        "            if \"dpt\" in model_id.lower():\n",
        "                # DPT models\n",
        "                processor = DPTImageProcessor.from_pretrained(model_id)\n",
        "                model = DPTForDepthEstimation.from_pretrained(model_id)\n",
        "            else:\n",
        "                # Other models\n",
        "                processor = AutoImageProcessor.from_pretrained(model_id)\n",
        "                model = AutoModelForDepthEstimation.from_pretrained(model_id)\n",
        "\n",
        "            model.to(self.device)\n",
        "            model.eval()\n",
        "\n",
        "            self.models[model_name] = {\n",
        "                'processor': processor,\n",
        "                'model': model,\n",
        "                'model_id': model_id\n",
        "            }\n",
        "\n",
        "            print(f\"âœ… {model_name} loaded successfully!\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Failed to load {model_name}: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def set_current_model(self, model_name: str):\n",
        "        \"\"\"Set the current active model\"\"\"\n",
        "        if model_name in self.models:\n",
        "            self.current_model = model_name\n",
        "            print(f\"ğŸ¯ Current model set to: {model_name}\")\n",
        "        else:\n",
        "            print(f\"âŒ Model {model_name} not found!\")\n",
        "\n",
        "    def list_available_models(self):\n",
        "        \"\"\"List all loaded models\"\"\"\n",
        "        print(\"ğŸ“‹ Available models:\")\n",
        "        for name, info in self.models.items():\n",
        "            status = \"ğŸ¯ ACTIVE\" if name == self.current_model else \"âšª INACTIVE\"\n",
        "            print(f\"  - {name} ({info['model_id']}) {status}\")\n",
        "\n",
        "# Initialize the depth estimator\n",
        "depth_estimator = DroneDepthEstimator()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591,
          "referenced_widgets": [
            "a7f5976634274c879f1d3d9071d436dd",
            "04f2006b801c49ac994e14dda9613ca0",
            "d394aa18a2d345acac71af8da5f298a1",
            "59c36bb463fc4c36b2b6945aa1537139",
            "165318b513894fd88016977bc15edcd4",
            "d8984019841d43e59ec046c07805225b",
            "acde8da87f6347e88042c6ff4a08af4b",
            "dfdff290eb124222ad1f775f4dffadbf",
            "f020b85b11074428ba1af568b0795cc9",
            "e645327a046f40399be038b5c8f78a10",
            "dca180df0ad446daa137ed50ab55f6d9",
            "b4be1c7f8cbc4bf5a910e35765671153",
            "688dcbd233e04215a29dfa4b3f4c3566",
            "a1b226390fc240b0b179f5341afc7f45",
            "574455c9fb5c436c87666dabe57b3cd6",
            "0f1d8bd738e446198e9ec380f61fabbf",
            "15f21e82ace04d8386924e33701fb740",
            "8cd9526fdaec4fa38e2348f3c4b07eb9",
            "6a9429c425924d29b0ee5508c7b49542",
            "06863808e7714f038907bf857c9937e4",
            "0ae9dc063b244eceac97088c09b0d083",
            "081665bb69f24fedbce98adb5e59c65c",
            "b577cd0777064530afa15bf425373d56",
            "4d75f185a19e4a76a8e0b612175df267",
            "d5b092dc74234aa799dfaabd606024e2",
            "6f62dc2f459c422d859fd2edede94a9a",
            "2914471209cc4f9f86fabf325d3e941f",
            "7983306679404064b424a8458d236bd5",
            "96b4f6c3dbb14af3ae7f972e2be983b1",
            "31881d7e817d427d8c25affe202012d5",
            "71c7bde17c0e4655bccb5bc193a6c924",
            "e4fd5eed6fcd42cea96901e708cdf80f",
            "f85a5370cf134241995ac5ea49728c05",
            "7fed554f46af4745b15054546fbe925f",
            "dde089dad6ac4a349ca28bda914cc13c",
            "62bd425afada400784bd251861f06e6b",
            "56928812992e404882ae75ee22a7d9ab",
            "3fb13a5fa2e74deb9b18fecb812778ca",
            "fa14f721551d4860b7e0b7974714c477",
            "604f04c826a8484689f031aeb9554c63",
            "2bbe7229509a4d7c83391cb1e3bb57c7",
            "e50b733e06494497b13deb1b9106cb19",
            "421a3ef395244f6e8c6775f4aed5ff8f",
            "e05f6d86a38540d38af5c8753723b901",
            "a852776517b84ae9bbd501d75625862a",
            "e55634abc4694f35b38621f3c844a821",
            "1fae395ee4924a738363d858be7e5040",
            "5c3202bd5f5c44f0bbe679c8f4b353f1",
            "eabfb58a7718403db6aa809a4753bacb",
            "37468c9dfd434ffaa5eb9b6c74c35ef5",
            "34a09449fa00495e9472d7cf468131d2",
            "d516f2b7ae2f4bb9b59bbe7c7353a39a",
            "a7f064a16ded422e965aec4bf5f70510",
            "93f87716bc434f1bb2bbaf28422e21e3",
            "1f9bf51e898a485a9be5ad273fb1e6e9",
            "184dea3b16bb463aa996c5b5f08fa962",
            "b485f9a4228741028bc7f08f7e86d4ff",
            "82948517d8cb4e6c9dd1f98db87813a9",
            "7bb37fe3c71c4e189aa330ec0045bc9e",
            "ec486de22aaa4c87a285ce338ebec300",
            "6fcb74276ca8486680c84c600f1ac072",
            "699e44e794034e7b9f0ef44e500ff357",
            "e71ce4d8444f49ee970a870c29a14f59",
            "43bbd9018f114218b095f0550cca5af8",
            "08e8d78ff45e4564a10280b25258b12c",
            "fe49b5bb84624a1f95b73e61a5f3763a",
            "96f28cb517eb4bc698c6a943e11af948",
            "9d3bcf3259744ec1b9ad96ab90e9362f",
            "1dcf88e1788b4319abc804a67a67e04b",
            "3aa9d63babb24a23b129791081e2dc02",
            "ae4bb369ce91426283ee58c65b5a6aa4",
            "f19c124e65db483ba37311dad819402e",
            "537ce407d1cb4b4abf5813cedc64ffe1",
            "1d9f1cc83dfb4eb29620b4e656e52e04",
            "b7124c220a4c46d2a5a13b405efc0914",
            "eacc0671253d4c4c95d99d14cd067457",
            "11d653070a46429f8aa8f84ff3f7ce6d"
          ]
        },
        "id": "xH6-tYBqf24Q",
        "outputId": "466a02ea-606d-4a01-8c1c-2580fafed52d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš€ Loading depth estimation models for drone navigation...\n",
            "\n",
            "ğŸ“¥ Loading DPT-Large...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a7f5976634274c879f1d3d9071d436dd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/285 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b4be1c7f8cbc4bf5a910e35765671153",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/942 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b577cd0777064530afa15bf425373d56",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.37G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DPTForDepthEstimation were not initialized from the model checkpoint at Intel/dpt-large and are newly initialized: ['neck.fusion_stage.layers.0.residual_layer1.convolution1.bias', 'neck.fusion_stage.layers.0.residual_layer1.convolution1.weight', 'neck.fusion_stage.layers.0.residual_layer1.convolution2.bias', 'neck.fusion_stage.layers.0.residual_layer1.convolution2.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… DPT-Large loaded successfully!\n",
            "ğŸ¯ Current model set to: DPT-Large\n",
            "\n",
            "ğŸ“¥ Loading DPT-Hybrid...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7fed554f46af4745b15054546fbe925f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/382 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a852776517b84ae9bbd501d75625862a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/9.88k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "184dea3b16bb463aa996c5b5f08fa962",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/490M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "96f28cb517eb4bc698c6a943e11af948",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/490M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… DPT-Hybrid loaded successfully!\n",
            "\n",
            "ğŸ“¥ Loading MiDaS...\n",
            "âŒ Failed to load MiDaS: Intel/midas-v2-1-small-256 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\n",
            "If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`\n",
            "\n",
            "ğŸ‰ Model loading complete!\n",
            "ğŸ“‹ Available models:\n",
            "  - DPT-Large (Intel/dpt-large) ğŸ¯ ACTIVE\n",
            "  - DPT-Hybrid (Intel/dpt-hybrid-midas) âšª INACTIVE\n"
          ]
        }
      ],
      "source": [
        "# Load multiple depth estimation models for comparison\n",
        "models_to_load = [\n",
        "    (\"DPT-Large\", \"Intel/dpt-large\"),\n",
        "    (\"DPT-Hybrid\", \"Intel/dpt-hybrid-midas\"),\n",
        "    (\"MiDaS\", \"Intel/midas-v2-1-small-256\"),\n",
        "]\n",
        "\n",
        "print(\"ğŸš€ Loading depth estimation models for drone navigation...\\n\")\n",
        "\n",
        "for model_name, model_id in models_to_load:\n",
        "    success = depth_estimator.load_model(model_name, model_id)\n",
        "    if success and depth_estimator.current_model is None:\n",
        "        depth_estimator.set_current_model(model_name)\n",
        "    print()\n",
        "\n",
        "print(\"ğŸ‰ Model loading complete!\")\n",
        "depth_estimator.list_available_models()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "kiTWTpz2f24R",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ§  Step 3: Core Depth Processing Functions\n",
        "\n",
        "These functions will form the foundation of our drone obstacle avoidance system:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PO6XszaZf24R"
      },
      "outputs": [],
      "source": [
        "def predict_depth(image: np.ndarray, model_name: str = None) -> Tuple[np.ndarray, Dict]:\n",
        "    \"\"\"\n",
        "    Predict depth map from image using specified model\n",
        "\n",
        "    Args:\n",
        "        image: Input RGB image (numpy array)\n",
        "        model_name: Name of model to use (if None, uses current model)\n",
        "\n",
        "    Returns:\n",
        "        depth_map: Depth map as numpy array\n",
        "        metadata: Processing metadata and statistics\n",
        "    \"\"\"\n",
        "    if model_name and model_name in depth_estimator.models:\n",
        "        model_info = depth_estimator.models[model_name]\n",
        "    elif depth_estimator.current_model:\n",
        "        model_info = depth_estimator.models[depth_estimator.current_model]\n",
        "        model_name = depth_estimator.current_model\n",
        "    else:\n",
        "        raise ValueError(\"No model available for depth prediction!\")\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Convert numpy array to PIL Image\n",
        "    if isinstance(image, np.ndarray):\n",
        "        if image.shape[2] == 3:  # RGB\n",
        "            pil_image = Image.fromarray(image)\n",
        "        else:\n",
        "            pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    else:\n",
        "        pil_image = image\n",
        "\n",
        "    # Process image\n",
        "    processor = model_info['processor']\n",
        "    model = model_info['model']\n",
        "\n",
        "    inputs = processor(images=pil_image, return_tensors=\"pt\").to(depth_estimator.device)\n",
        "\n",
        "    # Predict depth\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        predicted_depth = outputs.predicted_depth\n",
        "\n",
        "    # Convert to numpy and normalize\n",
        "    depth_map = predicted_depth.squeeze().cpu().numpy()\n",
        "\n",
        "    processing_time = time.time() - start_time\n",
        "\n",
        "    metadata = {\n",
        "        'model_used': model_name,\n",
        "        'processing_time': processing_time,\n",
        "        'min_depth': float(depth_map.min()),\n",
        "        'max_depth': float(depth_map.max()),\n",
        "        'mean_depth': float(depth_map.mean()),\n",
        "        'image_shape': image.shape,\n",
        "        'depth_shape': depth_map.shape\n",
        "    }\n",
        "\n",
        "    return depth_map, metadata\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yenQkzBpf24S"
      },
      "outputs": [],
      "source": [
        "def calibrate_depth_to_distance(depth_map: np.ndarray,\n",
        "                               min_distance: float = 0.5,\n",
        "                               max_distance: float = 10.0) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Calibrate relative depth values to real-world distances (meters)\n",
        "\n",
        "    Args:\n",
        "        depth_map: Raw depth map from model\n",
        "        min_distance: Minimum real-world distance in meters\n",
        "        max_distance: Maximum real-world distance in meters\n",
        "\n",
        "    Returns:\n",
        "        distance_map: Calibrated distance map in meters\n",
        "    \"\"\"\n",
        "    # Invert depth if needed (some models output inverse depth)\n",
        "    if depth_map.min() < 0:\n",
        "        depth_map = -depth_map\n",
        "\n",
        "    # Normalize to 0-1 range\n",
        "    depth_normalized = (depth_map - depth_map.min()) / (depth_map.max() - depth_map.min())\n",
        "\n",
        "    # Map to distance range (inverse relationship: closer objects = smaller depth values)\n",
        "    # For many models, smaller values represent closer objects\n",
        "    distance_map = min_distance + (1 - depth_normalized) * (max_distance - min_distance)\n",
        "\n",
        "    return distance_map\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸš Step 8: Test the Complete Pipeline\n",
        "\n",
        "Let's test our drone navigation system with different scenarios:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test with a single image\n",
        "def test_single_image(image_path: str, save_results: bool = True):\n",
        "    \"\"\"\n",
        "    Test the drone navigation system with a single image\n",
        "    \n",
        "    Args:\n",
        "        image_path: Path to test image\n",
        "        save_results: Whether to save analysis results\n",
        "    \"\"\"\n",
        "    print(f\"\\nğŸ” Analyzing: {image_path}\")\n",
        "    \n",
        "    # Load image\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        print(f\"âŒ Could not load image: {image_path}\")\n",
        "        return None\n",
        "    \n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    # Resize if too large (for faster processing)\n",
        "    max_size = 800\n",
        "    h, w = image.shape[:2]\n",
        "    if max(h, w) > max_size:\n",
        "        scale = max_size / max(h, w)\n",
        "        new_w, new_h = int(w * scale), int(h * scale)\n",
        "        image = cv2.resize(image, (new_w, new_h))\n",
        "        print(f\"ğŸ“ Resized image to {new_w}x{new_h}\")\n",
        "    \n",
        "    # Process image\n",
        "    results = process_drone_navigation(\n",
        "        image,\n",
        "        model_name=None,  # Use current model\n",
        "        min_distance=0.5,\n",
        "        max_distance=10.0,\n",
        "        danger_threshold=1.5,\n",
        "        warning_threshold=3.0,\n",
        "        safe_threshold=5.0\n",
        "    )\n",
        "    \n",
        "    # Display results\n",
        "    print(f\"\\nğŸ“Š Analysis Results:\")\n",
        "    print(f\"  â±ï¸  Processing time: {results['processing_time']:.2f} seconds\")\n",
        "    print(f\"  ğŸ¯ Model used: {results['depth_metadata']['model_used']}\")\n",
        "    print(f\"  ğŸš¨ Closest obstacle: {results['flight_analysis']['overall']['closest_obstacle']:.2f} meters\")\n",
        "    print(f\"  ğŸ§­ Navigation recommendation: {results['flight_analysis']['overall']['recommendation']}\")\n",
        "    print(f\"  ğŸ“Š Confidence: {results['flight_analysis']['overall']['confidence']:.1%}\")\n",
        "    \n",
        "    # Zone statistics\n",
        "    zone_stats = results['zone_statistics']\n",
        "    print(f\"\\nğŸ¨ Safety Zone Distribution:\")\n",
        "    print(f\"  ğŸ”´ Danger zone: {zone_stats['danger_percentage']:.1f}%\")\n",
        "    print(f\"  ğŸŸ  Warning zone: {zone_stats['warning_percentage']:.1f}%\")\n",
        "    print(f\"  ğŸŸ¡ Caution zone: {zone_stats['caution_percentage']:.1f}%\")\n",
        "    print(f\"  ğŸŸ¢ Safe zone: {zone_stats['safe_percentage']:.1f}%\")\n",
        "    \n",
        "    # Show visualization\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    plt.imshow(results['comprehensive_visualization'])\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Show directional analysis\n",
        "    results['directional_plot'].show()\n",
        "    \n",
        "    # Save results if requested\n",
        "    if save_results:\n",
        "        base_name = os.path.basename(image_path).split('.')[0]\n",
        "        output_path = f\"obstacle_analysis/{base_name}_analysis.jpg\"\n",
        "        cv2.imwrite(output_path, cv2.cvtColor(results['comprehensive_visualization'], cv2.COLOR_RGB2BGR))\n",
        "        print(f\"\\nğŸ’¾ Saved analysis to: {output_path}\")\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Test with the first downloaded image\n",
        "test_image_path = \"drone_test_images/forest_path.jpg\"\n",
        "if os.path.exists(test_image_path):\n",
        "    forest_results = test_single_image(test_image_path)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ”„ Step 9: Batch Processing and Comparison\n",
        "\n",
        "Let's test multiple scenarios and compare results:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Batch process all test images\n",
        "def batch_process_images():\n",
        "    \"\"\"Process all test images and create a comparison report\"\"\"\n",
        "    \n",
        "    test_images_dir = \"drone_test_images\"\n",
        "    image_files = [f for f in os.listdir(test_images_dir) if f.endswith('.jpg')]\n",
        "    \n",
        "    if not image_files:\n",
        "        print(\"âŒ No test images found!\")\n",
        "        return None\n",
        "    \n",
        "    results_summary = []\n",
        "    \n",
        "    print(f\"ğŸš Processing {len(image_files)} test images...\\n\")\n",
        "    \n",
        "    for img_file in image_files:\n",
        "        img_path = os.path.join(test_images_dir, img_file)\n",
        "        scenario_name = img_file.replace('.jpg', '').replace('_', ' ').title()\n",
        "        \n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"ğŸ“¸ Scenario: {scenario_name}\")\n",
        "        print(f\"{'='*60}\")\n",
        "        \n",
        "        try:\n",
        "            results = test_single_image(img_path, save_results=True)\n",
        "            \n",
        "            if results:\n",
        "                summary = {\n",
        "                    'scenario': scenario_name,\n",
        "                    'file': img_file,\n",
        "                    'processing_time': results['processing_time'],\n",
        "                    'closest_obstacle': results['flight_analysis']['overall']['closest_obstacle'],\n",
        "                    'recommendation': results['flight_analysis']['overall']['recommendation'],\n",
        "                    'confidence': results['flight_analysis']['overall']['confidence'],\n",
        "                    'danger_percentage': results['zone_statistics']['danger_percentage'],\n",
        "                    'safe_percentage': results['zone_statistics']['safe_percentage']\n",
        "                }\n",
        "                results_summary.append(summary)\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error processing {img_file}: {str(e)}\")\n",
        "    \n",
        "    return results_summary\n",
        "\n",
        "# Run batch processing\n",
        "all_results = batch_process_images()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ“Š Step 10: Results Analysis and Visualization\n",
        "\n",
        "Create comprehensive visualizations to compare different scenarios:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comparison visualization\n",
        "if all_results:\n",
        "    # Convert to DataFrame for easier analysis\n",
        "    import pandas as pd\n",
        "    df_results = pd.DataFrame(all_results)\n",
        "    \n",
        "    # Create comprehensive comparison plots\n",
        "    fig = make_subplots(\n",
        "        rows=2, cols=2,\n",
        "        subplot_titles=('Processing Time by Scenario', 'Closest Obstacle Distance',\n",
        "                       'Safety Zone Distribution', 'Navigation Recommendations'),\n",
        "        specs=[[{'type': 'bar'}, {'type': 'bar'}],\n",
        "               [{'type': 'bar'}, {'type': 'bar'}]]\n",
        "    )\n",
        "    \n",
        "    # 1. Processing Time\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=df_results['scenario'], y=df_results['processing_time'],\n",
        "               name='Processing Time (s)', marker_color='lightblue'),\n",
        "        row=1, col=1\n",
        "    )\n",
        "    \n",
        "    # 2. Closest Obstacle Distance\n",
        "    colors = ['red' if d < 1.5 else 'orange' if d < 3.0 else 'yellow' if d < 5.0 else 'green' \n",
        "              for d in df_results['closest_obstacle']]\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=df_results['scenario'], y=df_results['closest_obstacle'],\n",
        "               name='Distance (m)', marker_color=colors),\n",
        "        row=1, col=2\n",
        "    )\n",
        "    \n",
        "    # 3. Safety Zone Distribution\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=df_results['scenario'], y=df_results['danger_percentage'],\n",
        "               name='Danger %', marker_color='red'),\n",
        "        row=2, col=1\n",
        "    )\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=df_results['scenario'], y=df_results['safe_percentage'],\n",
        "               name='Safe %', marker_color='green'),\n",
        "        row=2, col=1\n",
        "    )\n",
        "    \n",
        "    # 4. Confidence Levels\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=df_results['scenario'], y=df_results['confidence'] * 100,\n",
        "               name='Confidence %', marker_color='purple'),\n",
        "        row=2, col=2\n",
        "    )\n",
        "    \n",
        "    # Update layout\n",
        "    fig.update_layout(\n",
        "        height=800,\n",
        "        showlegend=True,\n",
        "        title_text=\"ğŸš Drone Navigation Analysis Summary\",\n",
        "        title_font_size=20\n",
        "    )\n",
        "    \n",
        "    # Update axes\n",
        "    fig.update_xaxes(tickangle=45)\n",
        "    fig.update_yaxes(title_text=\"Time (s)\", row=1, col=1)\n",
        "    fig.update_yaxes(title_text=\"Distance (m)\", row=1, col=2)\n",
        "    fig.update_yaxes(title_text=\"Percentage\", row=2, col=1)\n",
        "    fig.update_yaxes(title_text=\"Confidence %\", row=2, col=2)\n",
        "    \n",
        "    fig.show()\n",
        "    \n",
        "    # Print summary table\n",
        "    print(\"\\nğŸ“‹ Summary Report:\")\n",
        "    print(\"=\"*100)\n",
        "    print(f\"{'Scenario':<20} {'Recommendation':<25} {'Closest Obstacle':<20} {'Confidence':<15}\")\n",
        "    print(\"=\"*100)\n",
        "    \n",
        "    for _, row in df_results.iterrows():\n",
        "        print(f\"{row['scenario']:<20} {row['recommendation']:<25} \"\n",
        "              f\"{row['closest_obstacle']:.1f}m{'':<15} {row['confidence']:.1%}\")\n",
        "    print(\"=\"*100)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ® Step 11: Interactive Gradio Interface\n",
        "\n",
        "Create an interactive web interface for real-time drone navigation testing:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gradio_process_image(input_image, \n",
        "                        min_distance, max_distance,\n",
        "                        danger_threshold, warning_threshold, safe_threshold,\n",
        "                        model_choice):\n",
        "    \"\"\"\n",
        "    Process image for Gradio interface\n",
        "    \"\"\"\n",
        "    if input_image is None:\n",
        "        return None, None, \"Please upload an image\"\n",
        "    \n",
        "    # Set the model\n",
        "    if model_choice in depth_estimator.models:\n",
        "        depth_estimator.set_current_model(model_choice)\n",
        "    \n",
        "    try:\n",
        "        # Process the image\n",
        "        results = process_drone_navigation(\n",
        "            input_image,\n",
        "            model_name=model_choice,\n",
        "            min_distance=min_distance,\n",
        "            max_distance=max_distance,\n",
        "            danger_threshold=danger_threshold,\n",
        "            warning_threshold=warning_threshold,\n",
        "            safe_threshold=safe_threshold\n",
        "        )\n",
        "        \n",
        "        # Create status message\n",
        "        status = f\"\"\"\n",
        "        ğŸš **Navigation Analysis Complete**\n",
        "        \n",
        "        **Flight Recommendation:** {results['flight_analysis']['overall']['recommendation'].replace('_', ' ')}\n",
        "        \n",
        "        **Safety Metrics:**\n",
        "        - ğŸš¨ Closest Obstacle: {results['flight_analysis']['overall']['closest_obstacle']:.1f} meters\n",
        "        - ğŸ“Š Confidence: {results['flight_analysis']['overall']['confidence']:.1%}\n",
        "        - ğŸ”´ Danger Zone: {results['zone_statistics']['danger_percentage']:.1f}%\n",
        "        - ğŸŸ¢ Safe Zone: {results['zone_statistics']['safe_percentage']:.1f}%\n",
        "        \n",
        "        **Processing Time:** {results['processing_time']:.2f} seconds\n",
        "        \"\"\"\n",
        "        \n",
        "        # Convert visualization to RGB\n",
        "        viz = cv2.cvtColor(results['comprehensive_visualization'], cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        # Create directional plot as image\n",
        "        directional_fig = results['directional_plot']\n",
        "        \n",
        "        return viz, directional_fig, status\n",
        "        \n",
        "    except Exception as e:\n",
        "        return None, None, f\"Error: {str(e)}\"\n",
        "\n",
        "# Create Gradio interface\n",
        "def create_gradio_interface():\n",
        "    \"\"\"Create and launch the Gradio interface\"\"\"\n",
        "    \n",
        "    with gr.Blocks(title=\"ğŸš Drone Obstacle Avoidance System\") as demo:\n",
        "        gr.Markdown(\"\"\"\n",
        "        # ğŸš Drone Obstacle Avoidance System\n",
        "        \n",
        "        Upload an image or use your webcam to test the drone navigation system.\n",
        "        Adjust the parameters to fine-tune the safety zones for your specific drone setup.\n",
        "        \"\"\")\n",
        "        \n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1):\n",
        "                # Input controls\n",
        "                input_image = gr.Image(label=\"Input Image\", type=\"numpy\")\n",
        "                \n",
        "                with gr.Group():\n",
        "                    gr.Markdown(\"### ğŸ›ï¸ Calibration Parameters\")\n",
        "                    min_distance = gr.Slider(0.1, 5.0, 0.5, \n",
        "                                           label=\"Min Distance (m)\",\n",
        "                                           info=\"Minimum detectable distance\")\n",
        "                    max_distance = gr.Slider(5.0, 50.0, 10.0,\n",
        "                                           label=\"Max Distance (m)\",\n",
        "                                           info=\"Maximum detectable distance\")\n",
        "                \n",
        "                with gr.Group():\n",
        "                    gr.Markdown(\"### ğŸš¨ Safety Thresholds\")\n",
        "                    danger_threshold = gr.Slider(0.5, 5.0, 1.5,\n",
        "                                               label=\"Danger Threshold (m)\",\n",
        "                                               info=\"Distance for immediate stop\")\n",
        "                    warning_threshold = gr.Slider(1.0, 10.0, 3.0,\n",
        "                                                label=\"Warning Threshold (m)\",\n",
        "                                                info=\"Distance for caution\")\n",
        "                    safe_threshold = gr.Slider(2.0, 15.0, 5.0,\n",
        "                                             label=\"Safe Threshold (m)\",\n",
        "                                             info=\"Distance for safe navigation\")\n",
        "                \n",
        "                model_choice = gr.Dropdown(\n",
        "                    choices=list(depth_estimator.models.keys()),\n",
        "                    value=depth_estimator.current_model,\n",
        "                    label=\"Depth Estimation Model\"\n",
        "                )\n",
        "                \n",
        "                process_btn = gr.Button(\"ğŸš€ Analyze Navigation\", variant=\"primary\")\n",
        "                \n",
        "            with gr.Column(scale=2):\n",
        "                # Output displays\n",
        "                output_viz = gr.Image(label=\"Navigation Analysis\")\n",
        "                directional_plot = gr.Plot(label=\"Directional Safety Analysis\")\n",
        "                status_text = gr.Markdown(label=\"Analysis Results\")\n",
        "        \n",
        "        # Example images\n",
        "        gr.Examples(\n",
        "            examples=[\n",
        "                [\"drone_test_images/forest_path.jpg\"],\n",
        "                [\"drone_test_images/urban_street.jpg\"],\n",
        "                [\"drone_test_images/corridor.jpg\"],\n",
        "                [\"drone_test_images/warehouse.jpg\"],\n",
        "                [\"drone_test_images/cluttered_room.jpg\"]\n",
        "            ],\n",
        "            inputs=input_image,\n",
        "            label=\"Example Scenarios\"\n",
        "        )\n",
        "        \n",
        "        # Connect the processing function\n",
        "        process_btn.click(\n",
        "            fn=gradio_process_image,\n",
        "            inputs=[input_image, min_distance, max_distance,\n",
        "                   danger_threshold, warning_threshold, safe_threshold,\n",
        "                   model_choice],\n",
        "            outputs=[output_viz, directional_plot, status_text]\n",
        "        )\n",
        "    \n",
        "    return demo\n",
        "\n",
        "# Launch the interface\n",
        "demo = create_gradio_interface()\n",
        "demo.launch(share=True)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ¥ Step 12: Real-time Video Processing\n",
        "\n",
        "Implement real-time video processing for live drone navigation:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DroneVideoProcessor:\n",
        "    \"\"\"\n",
        "    Real-time video processing for drone navigation\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, nav_analyzer, depth_estimator):\n",
        "        self.nav_analyzer = nav_analyzer\n",
        "        self.depth_estimator = depth_estimator\n",
        "        self.frame_skip = 5  # Process every nth frame for performance\n",
        "        self.frame_count = 0\n",
        "        self.last_recommendation = \"HOVER_AND_REASSESS\"\n",
        "        self.fps_tracker = []\n",
        "        \n",
        "    def process_frame(self, frame: np.ndarray) -> Tuple[np.ndarray, Dict]:\n",
        "        \"\"\"\n",
        "        Process a single video frame\n",
        "        \n",
        "        Args:\n",
        "            frame: Input frame (BGR)\n",
        "            \n",
        "        Returns:\n",
        "            processed_frame: Frame with navigation overlay\n",
        "            navigation_data: Navigation information\n",
        "        \"\"\"\n",
        "        self.frame_count += 1\n",
        "        start_time = time.time()\n",
        "        \n",
        "        # Skip frames for performance\n",
        "        if self.frame_count % self.frame_skip != 0:\n",
        "            # Return previous recommendation\n",
        "            return self._add_overlay(frame, None, cached=True), {}\n",
        "        \n",
        "        # Convert BGR to RGB\n",
        "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        # Resize for faster processing\n",
        "        h, w = frame.shape[:2]\n",
        "        processing_size = (640, 480)\n",
        "        resized_frame = cv2.resize(rgb_frame, processing_size)\n",
        "        \n",
        "        try:\n",
        "            # Predict depth\n",
        "            depth_map, _ = predict_depth(resized_frame)\n",
        "            \n",
        "            # Calibrate distances\n",
        "            distance_map = calibrate_depth_to_distance(depth_map, 0.5, 10.0)\n",
        "            \n",
        "            # Resize distance map back to original size\n",
        "            distance_map = cv2.resize(distance_map, (w, h))\n",
        "            \n",
        "            # Create safety zones\n",
        "            safety_zones, zone_stats = self.nav_analyzer.create_safety_zones(distance_map)\n",
        "            \n",
        "            # Analyze flight path\n",
        "            flight_analysis = self.nav_analyzer.analyze_flight_path(distance_map)\n",
        "            \n",
        "            # Update recommendation\n",
        "            self.last_recommendation = flight_analysis['overall']['recommendation']\n",
        "            \n",
        "            # Calculate FPS\n",
        "            process_time = time.time() - start_time\n",
        "            fps = 1.0 / process_time\n",
        "            self.fps_tracker.append(fps)\n",
        "            if len(self.fps_tracker) > 30:\n",
        "                self.fps_tracker.pop(0)\n",
        "            avg_fps = np.mean(self.fps_tracker)\n",
        "            \n",
        "            navigation_data = {\n",
        "                'recommendation': self.last_recommendation,\n",
        "                'closest_obstacle': flight_analysis['overall']['closest_obstacle'],\n",
        "                'confidence': flight_analysis['overall']['confidence'],\n",
        "                'fps': avg_fps,\n",
        "                'zone_stats': zone_stats\n",
        "            }\n",
        "            \n",
        "            # Add overlay to frame\n",
        "            processed_frame = self._add_overlay(frame, safety_zones, navigation_data)\n",
        "            \n",
        "            return processed_frame, navigation_data\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error processing frame: {e}\")\n",
        "            return frame, {}\n",
        "    \n",
        "    def _add_overlay(self, frame: np.ndarray, safety_zones: np.ndarray = None, \n",
        "                    navigation_data: Dict = None, cached: bool = False) -> np.ndarray:\n",
        "        \"\"\"Add navigation overlay to frame\"\"\"\n",
        "        \n",
        "        overlay = frame.copy()\n",
        "        h, w = frame.shape[:2]\n",
        "        \n",
        "        # Add safety zones overlay if available\n",
        "        if safety_zones is not None:\n",
        "            # Convert safety zones to BGR\n",
        "            safety_zones_bgr = cv2.cvtColor(safety_zones, cv2.COLOR_RGB2BGR)\n",
        "            overlay = cv2.addWeighted(overlay, 0.7, safety_zones_bgr, 0.3, 0)\n",
        "        \n",
        "        # Add navigation HUD\n",
        "        if navigation_data or cached:\n",
        "            # Background for text\n",
        "            cv2.rectangle(overlay, (10, 10), (w-10, 100), (0, 0, 0), -1)\n",
        "            cv2.rectangle(overlay, (10, 10), (w-10, 100), (0, 255, 0), 2)\n",
        "            \n",
        "            # Navigation recommendation\n",
        "            if cached:\n",
        "                rec_text = f\"RECOMMENDATION: {self.last_recommendation.replace('_', ' ')}\"\n",
        "            else:\n",
        "                rec_text = f\"RECOMMENDATION: {navigation_data['recommendation'].replace('_', ' ')}\"\n",
        "            \n",
        "            # Color based on recommendation\n",
        "            if \"EMERGENCY\" in rec_text or \"STOP\" in rec_text:\n",
        "                color = (0, 0, 255)  # Red\n",
        "            elif \"TURN\" in rec_text or \"CLIMB\" in rec_text:\n",
        "                color = (0, 165, 255)  # Orange\n",
        "            else:\n",
        "                color = (0, 255, 0)  # Green\n",
        "            \n",
        "            cv2.putText(overlay, rec_text, (20, 40), \n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
        "            \n",
        "            # Additional info if available\n",
        "            if navigation_data and not cached:\n",
        "                info_text = f\"Closest: {navigation_data['closest_obstacle']:.1f}m | \" \\\n",
        "                           f\"Confidence: {navigation_data['confidence']:.1%} | \" \\\n",
        "                           f\"FPS: {navigation_data['fps']:.1f}\"\n",
        "                cv2.putText(overlay, info_text, (20, 70),\n",
        "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
        "            \n",
        "            # Add directional indicators\n",
        "            center_x, center_y = w // 2, h // 2\n",
        "            \n",
        "            if \"LEFT\" in self.last_recommendation:\n",
        "                cv2.arrowedLine(overlay, (center_x, center_y), \n",
        "                               (center_x - 100, center_y), color, 5)\n",
        "            elif \"RIGHT\" in self.last_recommendation:\n",
        "                cv2.arrowedLine(overlay, (center_x, center_y), \n",
        "                               (center_x + 100, center_y), color, 5)\n",
        "            elif \"CLIMB\" in self.last_recommendation:\n",
        "                cv2.arrowedLine(overlay, (center_x, center_y), \n",
        "                               (center_x, center_y - 100), color, 5)\n",
        "        \n",
        "        return overlay\n",
        "\n",
        "# Create video processor instance\n",
        "video_processor = DroneVideoProcessor(nav_analyzer, depth_estimator)\n",
        "\n",
        "print(\"ğŸ¥ Video processor initialized!\")\n",
        "print(\"   - Processing every 5th frame for performance\")\n",
        "print(\"   - Real-time navigation overlay enabled\")\n",
        "print(\"   - FPS tracking enabled\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ’¾ Step 13: Save and Export Calibration\n",
        "\n",
        "Save calibration settings and model performance data for drone deployment:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_calibration_data(results_summary: List[Dict], \n",
        "                         calibration_params: Dict,\n",
        "                         model_performance: Dict):\n",
        "    \"\"\"\n",
        "    Save calibration data and model performance metrics\n",
        "    \"\"\"\n",
        "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "    \n",
        "    calibration_data = {\n",
        "        'timestamp': timestamp,\n",
        "        'calibration_parameters': calibration_params,\n",
        "        'model_performance': model_performance,\n",
        "        'test_results': results_summary,\n",
        "        'system_info': {\n",
        "            'device': depth_estimator.device,\n",
        "            'models_available': list(depth_estimator.models.keys()),\n",
        "            'current_model': depth_estimator.current_model\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    # Save JSON file\n",
        "    output_file = f\"calibration_data/drone_calibration_{timestamp}.json\"\n",
        "    with open(output_file, 'w') as f:\n",
        "        json.dump(calibration_data, f, indent=2)\n",
        "    \n",
        "    print(f\"ğŸ’¾ Calibration data saved to: {output_file}\")\n",
        "    \n",
        "    # Create summary report\n",
        "    report = f\"\"\"\n",
        "    # Drone Navigation Calibration Report\n",
        "    \n",
        "    Generated: {timestamp}\n",
        "    \n",
        "    ## System Configuration\n",
        "    - Device: {calibration_data['system_info']['device']}\n",
        "    - Current Model: {calibration_data['system_info']['current_model']}\n",
        "    - Available Models: {', '.join(calibration_data['system_info']['models_available'])}\n",
        "    \n",
        "    ## Calibration Parameters\n",
        "    - Min Distance: {calibration_params['min_distance']}m\n",
        "    - Max Distance: {calibration_params['max_distance']}m\n",
        "    - Danger Threshold: {calibration_params['danger_threshold']}m\n",
        "    - Warning Threshold: {calibration_params['warning_threshold']}m\n",
        "    - Safe Threshold: {calibration_params['safe_threshold']}m\n",
        "    \n",
        "    ## Performance Metrics\n",
        "    - Average Processing Time: {model_performance['avg_processing_time']:.3f}s\n",
        "    - Average FPS: {model_performance['avg_fps']:.1f}\n",
        "    - Success Rate: {model_performance['success_rate']:.1%}\n",
        "    \n",
        "    ## Test Scenarios Summary\n",
        "    Total Scenarios Tested: {len(results_summary)}\n",
        "    \"\"\"\n",
        "    \n",
        "    # Save report\n",
        "    report_file = f\"calibration_data/drone_calibration_report_{timestamp}.md\"\n",
        "    with open(report_file, 'w') as f:\n",
        "        f.write(report)\n",
        "    \n",
        "    print(f\"ğŸ“„ Calibration report saved to: {report_file}\")\n",
        "    \n",
        "    return calibration_data\n",
        "\n",
        "# Calculate performance metrics\n",
        "if all_results:\n",
        "    model_performance = {\n",
        "        'avg_processing_time': np.mean([r['processing_time'] for r in all_results]),\n",
        "        'avg_fps': 1.0 / np.mean([r['processing_time'] for r in all_results]),\n",
        "        'success_rate': len(all_results) / len(os.listdir(\"drone_test_images\"))\n",
        "    }\n",
        "    \n",
        "    calibration_params = {\n",
        "        'min_distance': 0.5,\n",
        "        'max_distance': 10.0,\n",
        "        'danger_threshold': 1.5,\n",
        "        'warning_threshold': 3.0,\n",
        "        'safe_threshold': 5.0\n",
        "    }\n",
        "    \n",
        "    # Save calibration\n",
        "    calibration_data = save_calibration_data(all_results, calibration_params, model_performance)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸš€ Step 14: Drone Integration Guide\n",
        "\n",
        "Here's how to integrate this system with your drone:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example drone integration class\n",
        "class DroneNavigationController:\n",
        "    \"\"\"\n",
        "    Example integration for drone flight controller\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, video_processor, calibration_data):\n",
        "        self.video_processor = video_processor\n",
        "        self.calibration = calibration_data\n",
        "        self.emergency_stop_enabled = True\n",
        "        self.max_speed = 5.0  # m/s\n",
        "        self.turn_rate = 30  # degrees/s\n",
        "        \n",
        "    def process_navigation_command(self, frame: np.ndarray) -> Dict:\n",
        "        \"\"\"\n",
        "        Process frame and return drone control commands\n",
        "        \n",
        "        Args:\n",
        "            frame: Current camera frame\n",
        "            \n",
        "        Returns:\n",
        "            control_commands: Dictionary with drone control parameters\n",
        "        \"\"\"\n",
        "        # Process frame\n",
        "        processed_frame, nav_data = self.video_processor.process_frame(frame)\n",
        "        \n",
        "        if not nav_data:\n",
        "            return self._get_default_commands()\n",
        "        \n",
        "        recommendation = nav_data['recommendation']\n",
        "        closest_obstacle = nav_data['closest_obstacle']\n",
        "        confidence = nav_data['confidence']\n",
        "        \n",
        "        # Generate control commands based on recommendation\n",
        "        commands = {\n",
        "            'timestamp': time.time(),\n",
        "            'raw_recommendation': recommendation,\n",
        "            'confidence': confidence\n",
        "        }\n",
        "        \n",
        "        # Emergency stop\n",
        "        if recommendation == \"EMERGENCY_STOP\" and self.emergency_stop_enabled:\n",
        "            commands.update({\n",
        "                'action': 'STOP',\n",
        "                'forward_speed': 0,\n",
        "                'lateral_speed': 0,\n",
        "                'vertical_speed': 0,\n",
        "                'yaw_rate': 0,\n",
        "                'emergency': True\n",
        "            })\n",
        "        \n",
        "        # Turn commands\n",
        "        elif recommendation == \"TURN_LEFT\":\n",
        "            speed_factor = min(1.0, closest_obstacle / 3.0)  # Slow down near obstacles\n",
        "            commands.update({\n",
        "                'action': 'TURN_LEFT',\n",
        "                'forward_speed': self.max_speed * speed_factor * 0.3,\n",
        "                'lateral_speed': -self.max_speed * speed_factor * 0.5,\n",
        "                'vertical_speed': 0,\n",
        "                'yaw_rate': -self.turn_rate,\n",
        "                'emergency': False\n",
        "            })\n",
        "        \n",
        "        elif recommendation == \"TURN_RIGHT\":\n",
        "            speed_factor = min(1.0, closest_obstacle / 3.0)\n",
        "            commands.update({\n",
        "                'action': 'TURN_RIGHT',\n",
        "                'forward_speed': self.max_speed * speed_factor * 0.3,\n",
        "                'lateral_speed': self.max_speed * speed_factor * 0.5,\n",
        "                'vertical_speed': 0,\n",
        "                'yaw_rate': self.turn_rate,\n",
        "                'emergency': False\n",
        "            })\n",
        "        \n",
        "        # Climb\n",
        "        elif recommendation == \"CLIMB\":\n",
        "            commands.update({\n",
        "                'action': 'CLIMB',\n",
        "                'forward_speed': 0,\n",
        "                'lateral_speed': 0,\n",
        "                'vertical_speed': self.max_speed * 0.5,\n",
        "                'yaw_rate': 0,\n",
        "                'emergency': False\n",
        "            })\n",
        "        \n",
        "        # Continue forward\n",
        "        elif recommendation == \"CONTINUE_FORWARD\":\n",
        "            speed_factor = min(1.0, (closest_obstacle - 1.5) / 3.5)  # Speed based on distance\n",
        "            commands.update({\n",
        "                'action': 'FORWARD',\n",
        "                'forward_speed': self.max_speed * speed_factor,\n",
        "                'lateral_speed': 0,\n",
        "                'vertical_speed': 0,\n",
        "                'yaw_rate': 0,\n",
        "                'emergency': False\n",
        "            })\n",
        "        \n",
        "        # Hover\n",
        "        else:\n",
        "            commands.update({\n",
        "                'action': 'HOVER',\n",
        "                'forward_speed': 0,\n",
        "                'lateral_speed': 0,\n",
        "                'vertical_speed': 0,\n",
        "                'yaw_rate': 0,\n",
        "                'emergency': False\n",
        "            })\n",
        "        \n",
        "        # Add safety limits\n",
        "        commands = self._apply_safety_limits(commands)\n",
        "        \n",
        "        return commands\n",
        "    \n",
        "    def _get_default_commands(self) -> Dict:\n",
        "        \"\"\"Get default hover commands\"\"\"\n",
        "        return {\n",
        "            'action': 'HOVER',\n",
        "            'forward_speed': 0,\n",
        "            'lateral_speed': 0,\n",
        "            'vertical_speed': 0,\n",
        "            'yaw_rate': 0,\n",
        "            'emergency': False,\n",
        "            'timestamp': time.time()\n",
        "        }\n",
        "    \n",
        "    def _apply_safety_limits(self, commands: Dict) -> Dict:\n",
        "        \"\"\"Apply safety limits to control commands\"\"\"\n",
        "        # Limit speeds\n",
        "        commands['forward_speed'] = np.clip(commands['forward_speed'], -self.max_speed, self.max_speed)\n",
        "        commands['lateral_speed'] = np.clip(commands['lateral_speed'], -self.max_speed, self.max_speed)\n",
        "        commands['vertical_speed'] = np.clip(commands['vertical_speed'], -self.max_speed * 0.5, self.max_speed * 0.5)\n",
        "        commands['yaw_rate'] = np.clip(commands['yaw_rate'], -self.turn_rate, self.turn_rate)\n",
        "        \n",
        "        return commands\n",
        "\n",
        "# Create drone controller\n",
        "drone_controller = DroneNavigationController(video_processor, calibration_data if 'calibration_data' in locals() else {})\n",
        "\n",
        "print(\"ğŸš Drone Navigation Controller initialized!\")\n",
        "print(\"   - Emergency stop: ENABLED\")\n",
        "print(\"   - Max speed: 5.0 m/s\")\n",
        "print(\"   - Turn rate: 30 deg/s\")\n",
        "print(\"\\nâš¡ Ready for integration with flight controller!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ¯ Summary and Next Steps\n",
        "\n",
        "Congratulations! You've built a complete drone obstacle avoidance system using Hugging Face's DepthEstimator. \n",
        "\n",
        "### ğŸ”§ What We've Built:\n",
        "1. **Depth Estimation Pipeline** - Multiple models for depth prediction\n",
        "2. **Distance Calibration** - Convert depth to real-world distances\n",
        "3. **Safety Zone Analysis** - Color-coded danger/warning/safe zones\n",
        "4. **Navigation Recommendations** - Real-time flight path suggestions\n",
        "5. **Batch Processing** - Test multiple scenarios\n",
        "6. **Interactive Interface** - Gradio UI for testing\n",
        "7. **Video Processing** - Real-time frame analysis\n",
        "8. **Drone Integration** - Example flight controller integration\n",
        "\n",
        "### ğŸ“ˆ Performance Metrics:\n",
        "- Processing speed suitable for real-time operation\n",
        "- Multiple safety thresholds for different flight scenarios\n",
        "- Confidence scoring for navigation decisions\n",
        "- FPS tracking for performance monitoring\n",
        "\n",
        "### ğŸš€ Next Steps:\n",
        "1. **Hardware Integration**:\n",
        "   - Connect to your drone's flight controller (PX4, ArduPilot, etc.)\n",
        "   - Integrate with onboard camera system\n",
        "   - Test with actual drone hardware\n",
        "\n",
        "2. **Performance Optimization**:\n",
        "   - Use TensorRT or ONNX for faster inference\n",
        "   - Implement edge computing solutions\n",
        "   - Optimize for specific hardware (Jetson, Raspberry Pi)\n",
        "\n",
        "3. **Advanced Features**:\n",
        "   - Add object detection for specific obstacle types\n",
        "   - Implement SLAM for mapping\n",
        "   - Add GPS integration for waypoint navigation\n",
        "   - Multi-camera support for 360Â° awareness\n",
        "\n",
        "4. **Safety Enhancements**:\n",
        "   - Add redundancy systems\n",
        "   - Implement fail-safe modes\n",
        "   - Add weather condition detection\n",
        "   - Create flight logs for analysis\n",
        "\n",
        "### ğŸ“š Resources:\n",
        "- [Hugging Face Depth Estimation Models](https://huggingface.co/models?pipeline_tag=depth-estimation)\n",
        "- [PX4 Autopilot Documentation](https://px4.io/)\n",
        "- [ArduPilot Documentation](https://ardupilot.org/)\n",
        "- [MAVLink Protocol](https://mavlink.io/)\n",
        "\n",
        "### âš ï¸ Safety Disclaimer:\n",
        "Always test thoroughly in controlled environments before deploying on actual drones. Follow local regulations and safety guidelines for drone operations.\n",
        "\n",
        "Happy Flying! ğŸšâœ¨\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "ofM7zLevf24S",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸš¨ Step 4: Obstacle Detection and Safety Zones\n",
        "\n",
        "Critical functions for drone safety and navigation:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uMoazfkf24S",
        "outputId": "b390fb83-3396-4e40-f5d5-da140403dac0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ§­ Navigation analyzer initialized with default safety thresholds\n"
          ]
        }
      ],
      "source": [
        "class DroneNavigationAnalyzer:\n",
        "    \"\"\"\n",
        "    Analyze depth maps for drone navigation and obstacle avoidance\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 danger_distance: float = 1.5,\n",
        "                 warning_distance: float = 3.0,\n",
        "                 safe_distance: float = 5.0):\n",
        "        \"\"\"\n",
        "        Initialize navigation analyzer with safety thresholds\n",
        "\n",
        "        Args:\n",
        "            danger_distance: Distance threshold for danger zone (meters)\n",
        "            warning_distance: Distance threshold for warning zone (meters)\n",
        "            safe_distance: Distance threshold for safe zone (meters)\n",
        "        \"\"\"\n",
        "        self.danger_distance = danger_distance\n",
        "        self.warning_distance = warning_distance\n",
        "        self.safe_distance = safe_distance\n",
        "\n",
        "    def create_safety_zones(self, distance_map: np.ndarray) -> Tuple[np.ndarray, Dict]:\n",
        "        \"\"\"\n",
        "        Create color-coded safety zones for navigation\n",
        "\n",
        "        Args:\n",
        "            distance_map: Distance map in meters\n",
        "\n",
        "        Returns:\n",
        "            safety_visualization: RGB image with color-coded zones\n",
        "            zone_statistics: Statistics for each zone\n",
        "        \"\"\"\n",
        "        h, w = distance_map.shape\n",
        "        safety_zones = np.zeros((h, w, 3), dtype=np.uint8)\n",
        "\n",
        "        # Define zone masks\n",
        "        danger_mask = distance_map < self.danger_distance\n",
        "        warning_mask = (distance_map >= self.danger_distance) & (distance_map < self.warning_distance)\n",
        "        caution_mask = (distance_map >= self.warning_distance) & (distance_map < self.safe_distance)\n",
        "        safe_mask = distance_map >= self.safe_distance\n",
        "\n",
        "        # Color-code zones (BGR format)\n",
        "        safety_zones[danger_mask] = [0, 0, 255]      # Red - DANGER\n",
        "        safety_zones[warning_mask] = [0, 165, 255]   # Orange - WARNING\n",
        "        safety_zones[caution_mask] = [0, 255, 255]   # Yellow - CAUTION\n",
        "        safety_zones[safe_mask] = [0, 255, 0]        # Green - SAFE\n",
        "\n",
        "        # Calculate statistics\n",
        "        total_pixels = h * w\n",
        "        zone_stats = {\n",
        "            'danger_pixels': np.sum(danger_mask),\n",
        "            'warning_pixels': np.sum(warning_mask),\n",
        "            'caution_pixels': np.sum(caution_mask),\n",
        "            'safe_pixels': np.sum(safe_mask),\n",
        "            'danger_percentage': (np.sum(danger_mask) / total_pixels) * 100,\n",
        "            'warning_percentage': (np.sum(warning_mask) / total_pixels) * 100,\n",
        "            'caution_percentage': (np.sum(caution_mask) / total_pixels) * 100,\n",
        "            'safe_percentage': (np.sum(safe_mask) / total_pixels) * 100,\n",
        "            'closest_obstacle': float(distance_map.min()),\n",
        "            'average_distance': float(distance_map.mean())\n",
        "        }\n",
        "\n",
        "        return safety_zones, zone_stats\n",
        "\n",
        "    def analyze_flight_path(self, distance_map: np.ndarray) -> Dict:\n",
        "        \"\"\"\n",
        "        Analyze the image for safe flight directions\n",
        "\n",
        "        Args:\n",
        "            distance_map: Distance map in meters\n",
        "\n",
        "        Returns:\n",
        "            flight_analysis: Recommended flight directions and safety assessment\n",
        "        \"\"\"\n",
        "        h, w = distance_map.shape\n",
        "\n",
        "        # Divide image into sectors for directional analysis\n",
        "        center_h, center_w = h // 2, w // 2\n",
        "\n",
        "        # Define sectors\n",
        "        sectors = {\n",
        "            'forward': distance_map[center_h-h//4:center_h+h//4, center_w-w//4:center_w+w//4],\n",
        "            'left': distance_map[:, :w//3],\n",
        "            'right': distance_map[:, 2*w//3:],\n",
        "            'up': distance_map[:h//3, :],\n",
        "            'down': distance_map[2*h//3:, :],\n",
        "            'forward_left': distance_map[center_h-h//4:center_h+h//4, :w//2],\n",
        "            'forward_right': distance_map[center_h-h//4:center_h+h//4, w//2:]\n",
        "        }\n",
        "\n",
        "        # Analyze each sector\n",
        "        analysis = {}\n",
        "        for direction, sector in sectors.items():\n",
        "            min_dist = float(sector.min())\n",
        "            mean_dist = float(sector.mean())\n",
        "\n",
        "            # Determine safety level\n",
        "            if min_dist < self.danger_distance:\n",
        "                safety_level = \"DANGER\"\n",
        "                recommendation = \"AVOID\"\n",
        "            elif min_dist < self.warning_distance:\n",
        "                safety_level = \"WARNING\"\n",
        "                recommendation = \"CAUTION\"\n",
        "            elif min_dist < self.safe_distance:\n",
        "                safety_level = \"CAUTION\"\n",
        "                recommendation = \"PROCEED_CAREFULLY\"\n",
        "            else:\n",
        "                safety_level = \"SAFE\"\n",
        "                recommendation = \"CLEAR\"\n",
        "\n",
        "            analysis[direction] = {\n",
        "                'min_distance': min_dist,\n",
        "                'mean_distance': mean_dist,\n",
        "                'safety_level': safety_level,\n",
        "                'recommendation': recommendation,\n",
        "                'safe_percentage': (np.sum(sector >= self.safe_distance) / sector.size) * 100\n",
        "            }\n",
        "\n",
        "        # Overall flight recommendation\n",
        "        forward_safety = analysis['forward']['safety_level']\n",
        "        closest_obstacle = float(distance_map.min())\n",
        "\n",
        "        if closest_obstacle < self.danger_distance:\n",
        "            overall_recommendation = \"EMERGENCY_STOP\"\n",
        "        elif forward_safety == \"SAFE\":\n",
        "            overall_recommendation = \"CONTINUE_FORWARD\"\n",
        "        elif analysis['left']['safety_level'] == \"SAFE\":\n",
        "            overall_recommendation = \"TURN_LEFT\"\n",
        "        elif analysis['right']['safety_level'] == \"SAFE\":\n",
        "            overall_recommendation = \"TURN_RIGHT\"\n",
        "        elif analysis['up']['safety_level'] == \"SAFE\":\n",
        "            overall_recommendation = \"CLIMB\"\n",
        "        else:\n",
        "            overall_recommendation = \"HOVER_AND_REASSESS\"\n",
        "\n",
        "        analysis['overall'] = {\n",
        "            'recommendation': overall_recommendation,\n",
        "            'closest_obstacle': closest_obstacle,\n",
        "            'confidence': self._calculate_confidence(analysis)\n",
        "        }\n",
        "\n",
        "        return analysis\n",
        "\n",
        "    def _calculate_confidence(self, analysis: Dict) -> float:\n",
        "        \"\"\"Calculate confidence score for navigation recommendations\"\"\"\n",
        "        # Simple confidence calculation based on distance margins\n",
        "        min_distances = [data['min_distance'] for data in analysis.values() if isinstance(data, dict)]\n",
        "        if not min_distances:\n",
        "            return 0.5\n",
        "\n",
        "        avg_min_distance = np.mean(min_distances)\n",
        "\n",
        "        if avg_min_distance >= self.safe_distance:\n",
        "            return 0.9\n",
        "        elif avg_min_distance >= self.warning_distance:\n",
        "            return 0.7\n",
        "        elif avg_min_distance >= self.danger_distance:\n",
        "            return 0.4\n",
        "        else:\n",
        "            return 0.2\n",
        "\n",
        "# Initialize navigation analyzer\n",
        "nav_analyzer = DroneNavigationAnalyzer()\n",
        "print(\"ğŸ§­ Navigation analyzer initialized with default safety thresholds\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "zyocXrxpf24T",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ¨ Step 5: Visualization Functions\n",
        "\n",
        "Create comprehensive visualizations for understanding the environment:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ZXIA43pzf24T"
      },
      "outputs": [],
      "source": [
        "def create_comprehensive_visualization(image: np.ndarray,\n",
        "                                     distance_map: np.ndarray,\n",
        "                                     safety_zones: np.ndarray,\n",
        "                                     flight_analysis: Dict,\n",
        "                                     zone_stats: Dict) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Create a comprehensive visualization for drone navigation\n",
        "\n",
        "    Args:\n",
        "        image: Original RGB image\n",
        "        distance_map: Distance map in meters\n",
        "        safety_zones: Color-coded safety zones\n",
        "        flight_analysis: Flight path analysis results\n",
        "        zone_stats: Zone statistics\n",
        "\n",
        "    Returns:\n",
        "        visualization: Combined visualization image\n",
        "    \"\"\"\n",
        "    h, w = image.shape[:2]\n",
        "\n",
        "    # Create a larger canvas for multiple views\n",
        "    canvas_height = h * 2 + 100  # Extra space for text\n",
        "    canvas_width = w * 2 + 100\n",
        "    canvas = np.zeros((canvas_height, canvas_width, 3), dtype=np.uint8)\n",
        "\n",
        "    # 1. Original image (top-left)\n",
        "    canvas[50:50+h, 50:50+w] = image\n",
        "\n",
        "    # 2. Distance heatmap (top-right)\n",
        "    distance_normalized = cv2.normalize(distance_map, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
        "    distance_colored = cv2.applyColorMap(distance_normalized, cv2.COLORMAP_VIRIDIS)\n",
        "    canvas[50:50+h, 50+w+50:50+w+50+w] = distance_colored\n",
        "\n",
        "    # 3. Safety zones (bottom-left)\n",
        "    canvas[50+h+50:50+h+50+h, 50:50+w] = safety_zones\n",
        "\n",
        "    # 4. Combined overlay (bottom-right)\n",
        "    overlay = cv2.addWeighted(image, 0.6, safety_zones, 0.4, 0)\n",
        "    canvas[50+h+50:50+h+50+h, 50+w+50:50+w+50+w] = overlay\n",
        "\n",
        "    # Add labels\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    font_scale = 0.8\n",
        "    color = (255, 255, 255)\n",
        "    thickness = 2\n",
        "\n",
        "    cv2.putText(canvas, \"Original Image\", (50, 30), font, font_scale, color, thickness)\n",
        "    cv2.putText(canvas, \"Distance Map\", (50+w+50, 30), font, font_scale, color, thickness)\n",
        "    cv2.putText(canvas, \"Safety Zones\", (50, 50+h+30), font, font_scale, color, thickness)\n",
        "    cv2.putText(canvas, \"Navigation Overlay\", (50+w+50, 50+h+30), font, font_scale, color, thickness)\n",
        "\n",
        "    # Add navigation recommendation\n",
        "    recommendation = flight_analysis['overall']['recommendation']\n",
        "    confidence = flight_analysis['overall']['confidence']\n",
        "    closest_dist = flight_analysis['overall']['closest_obstacle']\n",
        "\n",
        "    # Color-code recommendation\n",
        "    if recommendation == \"EMERGENCY_STOP\":\n",
        "        rec_color = (0, 0, 255)  # Red\n",
        "    elif recommendation in [\"TURN_LEFT\", \"TURN_RIGHT\", \"CLIMB\"]:\n",
        "        rec_color = (0, 165, 255)  # Orange\n",
        "    elif recommendation == \"CONTINUE_FORWARD\":\n",
        "        rec_color = (0, 255, 0)  # Green\n",
        "    else:\n",
        "        rec_color = (0, 255, 255)  # Yellow\n",
        "\n",
        "    # Add recommendation text\n",
        "    rec_text = f\"RECOMMENDATION: {recommendation.replace('_', ' ')}\"\n",
        "    cv2.putText(canvas, rec_text, (50, canvas_height - 60), font, 0.7, rec_color, 2)\n",
        "\n",
        "    conf_text = f\"Confidence: {confidence:.1%} | Closest: {closest_dist:.1f}m\"\n",
        "    cv2.putText(canvas, conf_text, (50, canvas_height - 30), font, 0.6, (255, 255, 255), 2)\n",
        "\n",
        "    return canvas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "fhy4Zf23f24U"
      },
      "outputs": [],
      "source": [
        "def create_directional_analysis_plot(flight_analysis: Dict):\n",
        "    \"\"\"\n",
        "    Create a plotly radar chart showing directional safety analysis\n",
        "    \"\"\"\n",
        "    directions = ['forward', 'left', 'right', 'up', 'down', 'forward_left', 'forward_right']\n",
        "\n",
        "    # Extract data for radar chart\n",
        "    min_distances = [flight_analysis[d]['min_distance'] for d in directions]\n",
        "    safety_percentages = [flight_analysis[d]['safe_percentage'] for d in directions]\n",
        "\n",
        "    # Create radar chart\n",
        "    fig = go.Figure()\n",
        "\n",
        "    fig.add_trace(go.Scatterpolar(\n",
        "        r=min_distances,\n",
        "        theta=directions,\n",
        "        fill='toself',\n",
        "        name='Min Distance (m)',\n",
        "        line_color='blue'\n",
        "    ))\n",
        "\n",
        "    fig.add_trace(go.Scatterpolar(\n",
        "        r=[d/20 for d in safety_percentages],  # Normalize to similar scale\n",
        "        theta=directions,\n",
        "        fill='toself',\n",
        "        name='Safety % (scaled)',\n",
        "        line_color='green',\n",
        "        opacity=0.6\n",
        "    ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        polar=dict(\n",
        "            radialaxis=dict(\n",
        "                visible=True,\n",
        "                range=[0, max(min_distances) * 1.1]\n",
        "            )),\n",
        "        showlegend=True,\n",
        "        title=\"ğŸ§­ Directional Safety Analysis\"\n",
        "    )\n",
        "\n",
        "    return fig\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "BPEwUnPzf24U",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ”§ Step 6: Complete Processing Pipeline\n",
        "\n",
        "Combine all functions into a comprehensive processing pipeline:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Txmk9lj3f24V"
      },
      "outputs": [],
      "source": [
        "def process_drone_navigation(image: np.ndarray,\n",
        "                           model_name: str = None,\n",
        "                           min_distance: float = 0.5,\n",
        "                           max_distance: float = 10.0,\n",
        "                           danger_threshold: float = 1.5,\n",
        "                           warning_threshold: float = 3.0,\n",
        "                           safe_threshold: float = 5.0) -> Dict:\n",
        "    \"\"\"\n",
        "    Complete pipeline for drone navigation analysis\n",
        "\n",
        "    Args:\n",
        "        image: Input RGB image\n",
        "        model_name: Depth estimation model to use\n",
        "        min_distance: Minimum calibration distance (meters)\n",
        "        max_distance: Maximum calibration distance (meters)\n",
        "        danger_threshold: Danger zone threshold (meters)\n",
        "        warning_threshold: Warning zone threshold (meters)\n",
        "        safe_threshold: Safe zone threshold (meters)\n",
        "\n",
        "    Returns:\n",
        "        results: Complete analysis results with visualizations\n",
        "    \"\"\"\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Step 1: Predict depth\n",
        "    print(\"ğŸ” Predicting depth...\")\n",
        "    depth_map, depth_metadata = predict_depth(image, model_name)\n",
        "\n",
        "    # Step 2: Calibrate to real-world distances\n",
        "    print(\"ğŸ“ Calibrating distances...\")\n",
        "    distance_map = calibrate_depth_to_distance(depth_map, min_distance, max_distance)\n",
        "\n",
        "    # Step 3: Update navigation analyzer thresholds\n",
        "    nav_analyzer.danger_distance = danger_threshold\n",
        "    nav_analyzer.warning_distance = warning_threshold\n",
        "    nav_analyzer.safe_distance = safe_threshold\n",
        "\n",
        "    # Step 4: Create safety zones\n",
        "    print(\"ğŸš¨ Analyzing safety zones...\")\n",
        "    safety_zones, zone_stats = nav_analyzer.create_safety_zones(distance_map)\n",
        "\n",
        "    # Step 5: Analyze flight paths\n",
        "    print(\"ğŸ§­ Analyzing flight paths...\")\n",
        "    flight_analysis = nav_analyzer.analyze_flight_path(distance_map)\n",
        "\n",
        "    # Step 6: Create visualizations\n",
        "    print(\"ğŸ¨ Creating visualizations...\")\n",
        "    comprehensive_viz = create_comprehensive_visualization(\n",
        "        image, distance_map, safety_zones, flight_analysis, zone_stats\n",
        "    )\n",
        "\n",
        "    # Create directional analysis plot\n",
        "    directional_plot = create_directional_analysis_plot(flight_analysis)\n",
        "\n",
        "    total_time = time.time() - start_time\n",
        "\n",
        "    # Compile results\n",
        "    results = {\n",
        "        'processing_time': total_time,\n",
        "        'depth_metadata': depth_metadata,\n",
        "        'distance_map': distance_map,\n",
        "        'safety_zones': safety_zones,\n",
        "        'zone_statistics': zone_stats,\n",
        "        'flight_analysis': flight_analysis,\n",
        "        'comprehensive_visualization': comprehensive_viz,\n",
        "        'directional_plot': directional_plot,\n",
        "        'calibration_params': {\n",
        "            'min_distance': min_distance,\n",
        "            'max_distance': max_distance,\n",
        "            'danger_threshold': danger_threshold,\n",
        "            'warning_threshold': warning_threshold,\n",
        "            'safe_threshold': safe_threshold\n",
        "        }\n",
        "    }\n",
        "\n",
        "    print(f\"âœ… Analysis complete in {total_time:.2f} seconds\")\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "NNd9lH3Of24V",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ“¥ Step 7: Download Test Images\n",
        "\n",
        "Download test images that simulate different drone navigation scenarios:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZFuMui0f24V",
        "outputId": "da09b505-1724-4039-9d76-d9729f709968"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“¥ Downloading test images...\n",
            "âœ… Downloaded: forest_path\n",
            "âœ… Downloaded: urban_street\n",
            "âœ… Downloaded: corridor\n",
            "âœ… Downloaded: warehouse\n",
            "âœ… Downloaded: cluttered_room\n",
            "\n",
            "ğŸ‰ Test images ready for drone navigation analysis!\n"
          ]
        }
      ],
      "source": [
        "# Download test images for different drone scenarios\n",
        "test_images = [\n",
        "    # Outdoor scenarios\n",
        "    (\"forest_path\", \"https://images.unsplash.com/photo-1441974231531-c6227db76b6e\"),\n",
        "    (\"urban_street\", \"https://images.unsplash.com/photo-1506905925346-21bda4d32df4\"),\n",
        "    # (\"mountain_view\", \"https://images.unsplash.com/photo-1464822759844-d150baef493e\"),\n",
        "\n",
        "    # Indoor scenarios\n",
        "    (\"corridor\", \"https://images.unsplash.com/photo-1586023492125-27b2c045efd7\"),\n",
        "    (\"warehouse\", \"https://images.unsplash.com/photo-1553062407-98eeb64c6a62\"),\n",
        "\n",
        "    # Complex scenarios\n",
        "    (\"cluttered_room\", \"https://images.unsplash.com/photo-1555041469-a586c61ea9bc\"),\n",
        "]\n",
        "\n",
        "print(\"ğŸ“¥ Downloading test images...\")\n",
        "import urllib.request\n",
        "\n",
        "for name, url in test_images:\n",
        "    try:\n",
        "        filename = f\"drone_test_images/{name}.jpg\"\n",
        "        urllib.request.urlretrieve(url, filename)\n",
        "        print(f\"âœ… Downloaded: {name}\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Failed to download {name}: {str(e)}\")\n",
        "\n",
        "print(\"\\nğŸ‰ Test images ready for drone navigation analysis!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸš Step 8: Test the Complete Pipeline\n",
        "\n",
        "Let's test our drone navigation system with different scenarios:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test with a single image\n",
        "def test_single_image(image_path: str, save_results: bool = True):\n",
        "    \"\"\"\n",
        "    Test the drone navigation system with a single image\n",
        "    \n",
        "    Args:\n",
        "        image_path: Path to test image\n",
        "        save_results: Whether to save analysis results\n",
        "    \"\"\"\n",
        "    print(f\"\\nğŸ” Analyzing: {image_path}\")\n",
        "    \n",
        "    # Load image\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        print(f\"âŒ Could not load image: {image_path}\")\n",
        "        return None\n",
        "    \n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    # Resize if too large (for faster processing)\n",
        "    max_size = 800\n",
        "    h, w = image.shape[:2]\n",
        "    if max(h, w) > max_size:\n",
        "        scale = max_size / max(h, w)\n",
        "        new_w, new_h = int(w * scale), int(h * scale)\n",
        "        image = cv2.resize(image, (new_w, new_h))\n",
        "        print(f\"ğŸ“ Resized image to {new_w}x{new_h}\")\n",
        "    \n",
        "    # Process image\n",
        "    results = process_drone_navigation(\n",
        "        image,\n",
        "        model_name=None,  # Use current model\n",
        "        min_distance=0.5,\n",
        "        max_distance=10.0,\n",
        "        danger_threshold=1.5,\n",
        "        warning_threshold=3.0,\n",
        "        safe_threshold=5.0\n",
        "    )\n",
        "    \n",
        "    # Display results\n",
        "    print(f\"\\nğŸ“Š Analysis Results:\")\n",
        "    print(f\"  â±ï¸  Processing time: {results['processing_time']:.2f} seconds\")\n",
        "    print(f\"  ğŸ¯ Model used: {results['depth_metadata']['model_used']}\")\n",
        "    print(f\"  ğŸš¨ Closest obstacle: {results['flight_analysis']['overall']['closest_obstacle']:.2f} meters\")\n",
        "    print(f\"  ğŸ§­ Navigation recommendation: {results['flight_analysis']['overall']['recommendation']}\")\n",
        "    print(f\"  ğŸ“Š Confidence: {results['flight_analysis']['overall']['confidence']:.1%}\")\n",
        "    \n",
        "    # Zone statistics\n",
        "    zone_stats = results['zone_statistics']\n",
        "    print(f\"\\nğŸ¨ Safety Zone Distribution:\")\n",
        "    print(f\"  ğŸ”´ Danger zone: {zone_stats['danger_percentage']:.1f}%\")\n",
        "    print(f\"  ğŸŸ  Warning zone: {zone_stats['warning_percentage']:.1f}%\")\n",
        "    print(f\"  ğŸŸ¡ Caution zone: {zone_stats['caution_percentage']:.1f}%\")\n",
        "    print(f\"  ğŸŸ¢ Safe zone: {zone_stats['safe_percentage']:.1f}%\")\n",
        "    \n",
        "    # Show visualization\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    plt.imshow(results['comprehensive_visualization'])\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Show directional analysis\n",
        "    results['directional_plot'].show()\n",
        "    \n",
        "    # Save results if requested\n",
        "    if save_results:\n",
        "        base_name = os.path.basename(image_path).split('.')[0]\n",
        "        output_path = f\"obstacle_analysis/{base_name}_analysis.jpg\"\n",
        "        cv2.imwrite(output_path, cv2.cvtColor(results['comprehensive_visualization'], cv2.COLOR_RGB2BGR))\n",
        "        print(f\"\\nğŸ’¾ Saved analysis to: {output_path}\")\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Test with the first downloaded image\n",
        "test_image_path = \"drone_test_images/forest_path.jpg\"\n",
        "if os.path.exists(test_image_path):\n",
        "    forest_results = test_single_image(test_image_path)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ”„ Step 9: Batch Processing and Comparison\n",
        "\n",
        "Let's test multiple scenarios and compare results:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Batch process all test images\n",
        "def batch_process_images():\n",
        "    \"\"\"Process all test images and create a comparison report\"\"\"\n",
        "    \n",
        "    test_images_dir = \"drone_test_images\"\n",
        "    image_files = [f for f in os.listdir(test_images_dir) if f.endswith('.jpg')]\n",
        "    \n",
        "    if not image_files:\n",
        "        print(\"âŒ No test images found!\")\n",
        "        return None\n",
        "    \n",
        "    results_summary = []\n",
        "    \n",
        "    print(f\"ğŸš Processing {len(image_files)} test images...\\n\")\n",
        "    \n",
        "    for img_file in image_files:\n",
        "        img_path = os.path.join(test_images_dir, img_file)\n",
        "        scenario_name = img_file.replace('.jpg', '').replace('_', ' ').title()\n",
        "        \n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"ğŸ“¸ Scenario: {scenario_name}\")\n",
        "        print(f\"{'='*60}\")\n",
        "        \n",
        "        try:\n",
        "            results = test_single_image(img_path, save_results=True)\n",
        "            \n",
        "            if results:\n",
        "                summary = {\n",
        "                    'scenario': scenario_name,\n",
        "                    'file': img_file,\n",
        "                    'processing_time': results['processing_time'],\n",
        "                    'closest_obstacle': results['flight_analysis']['overall']['closest_obstacle'],\n",
        "                    'recommendation': results['flight_analysis']['overall']['recommendation'],\n",
        "                    'confidence': results['flight_analysis']['overall']['confidence'],\n",
        "                    'danger_percentage': results['zone_statistics']['danger_percentage'],\n",
        "                    'safe_percentage': results['zone_statistics']['safe_percentage']\n",
        "                }\n",
        "                results_summary.append(summary)\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error processing {img_file}: {str(e)}\")\n",
        "    \n",
        "    return results_summary\n",
        "\n",
        "# Run batch processing\n",
        "all_results = batch_process_images()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ“Š Step 10: Results Analysis and Visualization\n",
        "\n",
        "Create comprehensive visualizations to compare different scenarios:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comparison visualization\n",
        "if all_results:\n",
        "    # Convert to DataFrame for easier analysis\n",
        "    import pandas as pd\n",
        "    df_results = pd.DataFrame(all_results)\n",
        "    \n",
        "    # Create comprehensive comparison plots\n",
        "    fig = make_subplots(\n",
        "        rows=2, cols=2,\n",
        "        subplot_titles=('Processing Time by Scenario', 'Closest Obstacle Distance',\n",
        "                       'Safety Zone Distribution', 'Navigation Recommendations'),\n",
        "        specs=[[{'type': 'bar'}, {'type': 'bar'}],\n",
        "               [{'type': 'bar'}, {'type': 'bar'}]]\n",
        "    )\n",
        "    \n",
        "    # 1. Processing Time\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=df_results['scenario'], y=df_results['processing_time'],\n",
        "               name='Processing Time (s)', marker_color='lightblue'),\n",
        "        row=1, col=1\n",
        "    )\n",
        "    \n",
        "    # 2. Closest Obstacle Distance\n",
        "    colors = ['red' if d < 1.5 else 'orange' if d < 3.0 else 'yellow' if d < 5.0 else 'green' \n",
        "              for d in df_results['closest_obstacle']]\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=df_results['scenario'], y=df_results['closest_obstacle'],\n",
        "               name='Distance (m)', marker_color=colors),\n",
        "        row=1, col=2\n",
        "    )\n",
        "    \n",
        "    # 3. Safety Zone Distribution\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=df_results['scenario'], y=df_results['danger_percentage'],\n",
        "               name='Danger %', marker_color='red'),\n",
        "        row=2, col=1\n",
        "    )\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=df_results['scenario'], y=df_results['safe_percentage'],\n",
        "               name='Safe %', marker_color='green'),\n",
        "        row=2, col=1\n",
        "    )\n",
        "    \n",
        "    # 4. Confidence Levels\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=df_results['scenario'], y=df_results['confidence'] * 100,\n",
        "               name='Confidence %', marker_color='purple'),\n",
        "        row=2, col=2\n",
        "    )\n",
        "    \n",
        "    # Update layout\n",
        "    fig.update_layout(\n",
        "        height=800,\n",
        "        showlegend=True,\n",
        "        title_text=\"ğŸš Drone Navigation Analysis Summary\",\n",
        "        title_font_size=20\n",
        "    )\n",
        "    \n",
        "    # Update axes\n",
        "    fig.update_xaxes(tickangle=45)\n",
        "    fig.update_yaxes(title_text=\"Time (s)\", row=1, col=1)\n",
        "    fig.update_yaxes(title_text=\"Distance (m)\", row=1, col=2)\n",
        "    fig.update_yaxes(title_text=\"Percentage\", row=2, col=1)\n",
        "    fig.update_yaxes(title_text=\"Confidence %\", row=2, col=2)\n",
        "    \n",
        "    fig.show()\n",
        "    \n",
        "    # Print summary table\n",
        "    print(\"\\nğŸ“‹ Summary Report:\")\n",
        "    print(\"=\"*100)\n",
        "    print(f\"{'Scenario':<20} {'Recommendation':<25} {'Closest Obstacle':<20} {'Confidence':<15}\")\n",
        "    print(\"=\"*100)\n",
        "    \n",
        "    for _, row in df_results.iterrows():\n",
        "        print(f\"{row['scenario']:<20} {row['recommendation']:<25} \"\n",
        "              f\"{row['closest_obstacle']:.1f}m{'':<15} {row['confidence']:.1%}\")\n",
        "    print(\"=\"*100)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ® Step 11: Interactive Gradio Interface\n",
        "\n",
        "Create an interactive web interface for real-time drone navigation testing:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gradio_process_image(input_image, \n",
        "                        min_distance, max_distance,\n",
        "                        danger_threshold, warning_threshold, safe_threshold,\n",
        "                        model_choice):\n",
        "    \"\"\"\n",
        "    Process image for Gradio interface\n",
        "    \"\"\"\n",
        "    if input_image is None:\n",
        "        return None, None, \"Please upload an image\"\n",
        "    \n",
        "    # Set the model\n",
        "    if model_choice in depth_estimator.models:\n",
        "        depth_estimator.set_current_model(model_choice)\n",
        "    \n",
        "    try:\n",
        "        # Process the image\n",
        "        results = process_drone_navigation(\n",
        "            input_image,\n",
        "            model_name=model_choice,\n",
        "            min_distance=min_distance,\n",
        "            max_distance=max_distance,\n",
        "            danger_threshold=danger_threshold,\n",
        "            warning_threshold=warning_threshold,\n",
        "            safe_threshold=safe_threshold\n",
        "        )\n",
        "        \n",
        "        # Create status message\n",
        "        status = f\"\"\"\n",
        "        ğŸš **Navigation Analysis Complete**\n",
        "        \n",
        "        **Flight Recommendation:** {results['flight_analysis']['overall']['recommendation'].replace('_', ' ')}\n",
        "        \n",
        "        **Safety Metrics:**\n",
        "        - ğŸš¨ Closest Obstacle: {results['flight_analysis']['overall']['closest_obstacle']:.1f} meters\n",
        "        - ğŸ“Š Confidence: {results['flight_analysis']['overall']['confidence']:.1%}\n",
        "        - ğŸ”´ Danger Zone: {results['zone_statistics']['danger_percentage']:.1f}%\n",
        "        - ğŸŸ¢ Safe Zone: {results['zone_statistics']['safe_percentage']:.1f}%\n",
        "        \n",
        "        **Processing Time:** {results['processing_time']:.2f} seconds\n",
        "        \"\"\"\n",
        "        \n",
        "        # Convert visualization to RGB\n",
        "        viz = cv2.cvtColor(results['comprehensive_visualization'], cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        # Create directional plot as image\n",
        "        directional_fig = results['directional_plot']\n",
        "        \n",
        "        return viz, directional_fig, status\n",
        "        \n",
        "    except Exception as e:\n",
        "        return None, None, f\"Error: {str(e)}\"\n",
        "\n",
        "# Create Gradio interface\n",
        "def create_gradio_interface():\n",
        "    \"\"\"Create and launch the Gradio interface\"\"\"\n",
        "    \n",
        "    with gr.Blocks(title=\"ğŸš Drone Obstacle Avoidance System\") as demo:\n",
        "        gr.Markdown(\"\"\"\n",
        "        # ğŸš Drone Obstacle Avoidance System\n",
        "        \n",
        "        Upload an image or use your webcam to test the drone navigation system.\n",
        "        Adjust the parameters to fine-tune the safety zones for your specific drone setup.\n",
        "        \"\"\")\n",
        "        \n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1):\n",
        "                # Input controls\n",
        "                input_image = gr.Image(label=\"Input Image\", type=\"numpy\")\n",
        "                \n",
        "                with gr.Group():\n",
        "                    gr.Markdown(\"### ğŸ›ï¸ Calibration Parameters\")\n",
        "                    min_distance = gr.Slider(0.1, 5.0, 0.5, \n",
        "                                           label=\"Min Distance (m)\",\n",
        "                                           info=\"Minimum detectable distance\")\n",
        "                    max_distance = gr.Slider(5.0, 50.0, 10.0,\n",
        "                                           label=\"Max Distance (m)\",\n",
        "                                           info=\"Maximum detectable distance\")\n",
        "                \n",
        "                with gr.Group():\n",
        "                    gr.Markdown(\"### ğŸš¨ Safety Thresholds\")\n",
        "                    danger_threshold = gr.Slider(0.5, 5.0, 1.5,\n",
        "                                               label=\"Danger Threshold (m)\",\n",
        "                                               info=\"Distance for immediate stop\")\n",
        "                    warning_threshold = gr.Slider(1.0, 10.0, 3.0,\n",
        "                                                label=\"Warning Threshold (m)\",\n",
        "                                                info=\"Distance for caution\")\n",
        "                    safe_threshold = gr.Slider(2.0, 15.0, 5.0,\n",
        "                                             label=\"Safe Threshold (m)\",\n",
        "                                             info=\"Distance for safe navigation\")\n",
        "                \n",
        "                model_choice = gr.Dropdown(\n",
        "                    choices=list(depth_estimator.models.keys()),\n",
        "                    value=depth_estimator.current_model,\n",
        "                    label=\"Depth Estimation Model\"\n",
        "                )\n",
        "                \n",
        "                process_btn = gr.Button(\"ğŸš€ Analyze Navigation\", variant=\"primary\")\n",
        "                \n",
        "            with gr.Column(scale=2):\n",
        "                # Output displays\n",
        "                output_viz = gr.Image(label=\"Navigation Analysis\")\n",
        "                directional_plot = gr.Plot(label=\"Directional Safety Analysis\")\n",
        "                status_text = gr.Markdown(label=\"Analysis Results\")\n",
        "        \n",
        "        # Example images\n",
        "        gr.Examples(\n",
        "            examples=[\n",
        "                [\"drone_test_images/forest_path.jpg\"],\n",
        "                [\"drone_test_images/urban_street.jpg\"],\n",
        "                [\"drone_test_images/corridor.jpg\"],\n",
        "                [\"drone_test_images/warehouse.jpg\"],\n",
        "                [\"drone_test_images/cluttered_room.jpg\"]\n",
        "            ],\n",
        "            inputs=input_image,\n",
        "            label=\"Example Scenarios\"\n",
        "        )\n",
        "        \n",
        "        # Connect the processing function\n",
        "        process_btn.click(\n",
        "            fn=gradio_process_image,\n",
        "            inputs=[input_image, min_distance, max_distance,\n",
        "                   danger_threshold, warning_threshold, safe_threshold,\n",
        "                   model_choice],\n",
        "            outputs=[output_viz, directional_plot, status_text]\n",
        "        )\n",
        "    \n",
        "    return demo\n",
        "\n",
        "# Launch the interface\n",
        "demo = create_gradio_interface()\n",
        "demo.launch(share=True)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ¥ Step 12: Real-time Video Processing\n",
        "\n",
        "Implement real-time video processing for live drone navigation:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DroneVideoProcessor:\n",
        "    \"\"\"\n",
        "    Real-time video processing for drone navigation\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, nav_analyzer, depth_estimator):\n",
        "        self.nav_analyzer = nav_analyzer\n",
        "        self.depth_estimator = depth_estimator\n",
        "        self.frame_skip = 5  # Process every nth frame for performance\n",
        "        self.frame_count = 0\n",
        "        self.last_recommendation = \"HOVER_AND_REASSESS\"\n",
        "        self.fps_tracker = []\n",
        "        \n",
        "    def process_frame(self, frame: np.ndarray) -> Tuple[np.ndarray, Dict]:\n",
        "        \"\"\"\n",
        "        Process a single video frame\n",
        "        \n",
        "        Args:\n",
        "            frame: Input frame (BGR)\n",
        "            \n",
        "        Returns:\n",
        "            processed_frame: Frame with navigation overlay\n",
        "            navigation_data: Navigation information\n",
        "        \"\"\"\n",
        "        self.frame_count += 1\n",
        "        start_time = time.time()\n",
        "        \n",
        "        # Skip frames for performance\n",
        "        if self.frame_count % self.frame_skip != 0:\n",
        "            # Return previous recommendation\n",
        "            return self._add_overlay(frame, None, cached=True), {}\n",
        "        \n",
        "        # Convert BGR to RGB\n",
        "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        # Resize for faster processing\n",
        "        h, w = frame.shape[:2]\n",
        "        processing_size = (640, 480)\n",
        "        resized_frame = cv2.resize(rgb_frame, processing_size)\n",
        "        \n",
        "        try:\n",
        "            # Predict depth\n",
        "            depth_map, _ = predict_depth(resized_frame)\n",
        "            \n",
        "            # Calibrate distances\n",
        "            distance_map = calibrate_depth_to_distance(depth_map, 0.5, 10.0)\n",
        "            \n",
        "            # Resize distance map back to original size\n",
        "            distance_map = cv2.resize(distance_map, (w, h))\n",
        "            \n",
        "            # Create safety zones\n",
        "            safety_zones, zone_stats = self.nav_analyzer.create_safety_zones(distance_map)\n",
        "            \n",
        "            # Analyze flight path\n",
        "            flight_analysis = self.nav_analyzer.analyze_flight_path(distance_map)\n",
        "            \n",
        "            # Update recommendation\n",
        "            self.last_recommendation = flight_analysis['overall']['recommendation']\n",
        "            \n",
        "            # Calculate FPS\n",
        "            process_time = time.time() - start_time\n",
        "            fps = 1.0 / process_time\n",
        "            self.fps_tracker.append(fps)\n",
        "            if len(self.fps_tracker) > 30:\n",
        "                self.fps_tracker.pop(0)\n",
        "            avg_fps = np.mean(self.fps_tracker)\n",
        "            \n",
        "            navigation_data = {\n",
        "                'recommendation': self.last_recommendation,\n",
        "                'closest_obstacle': flight_analysis['overall']['closest_obstacle'],\n",
        "                'confidence': flight_analysis['overall']['confidence'],\n",
        "                'fps': avg_fps,\n",
        "                'zone_stats': zone_stats\n",
        "            }\n",
        "            \n",
        "            # Add overlay to frame\n",
        "            processed_frame = self._add_overlay(frame, safety_zones, navigation_data)\n",
        "            \n",
        "            return processed_frame, navigation_data\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error processing frame: {e}\")\n",
        "            return frame, {}\n",
        "    \n",
        "    def _add_overlay(self, frame: np.ndarray, safety_zones: np.ndarray = None, \n",
        "                    navigation_data: Dict = None, cached: bool = False) -> np.ndarray:\n",
        "        \"\"\"Add navigation overlay to frame\"\"\"\n",
        "        \n",
        "        overlay = frame.copy()\n",
        "        h, w = frame.shape[:2]\n",
        "        \n",
        "        # Add safety zones overlay if available\n",
        "        if safety_zones is not None:\n",
        "            # Convert safety zones to BGR\n",
        "            safety_zones_bgr = cv2.cvtColor(safety_zones, cv2.COLOR_RGB2BGR)\n",
        "            overlay = cv2.addWeighted(overlay, 0.7, safety_zones_bgr, 0.3, 0)\n",
        "        \n",
        "        # Add navigation HUD\n",
        "        if navigation_data or cached:\n",
        "            # Background for text\n",
        "            cv2.rectangle(overlay, (10, 10), (w-10, 100), (0, 0, 0), -1)\n",
        "            cv2.rectangle(overlay, (10, 10), (w-10, 100), (0, 255, 0), 2)\n",
        "            \n",
        "            # Navigation recommendation\n",
        "            if cached:\n",
        "                rec_text = f\"RECOMMENDATION: {self.last_recommendation.replace('_', ' ')}\"\n",
        "            else:\n",
        "                rec_text = f\"RECOMMENDATION: {navigation_data['recommendation'].replace('_', ' ')}\"\n",
        "            \n",
        "            # Color based on recommendation\n",
        "            if \"EMERGENCY\" in rec_text or \"STOP\" in rec_text:\n",
        "                color = (0, 0, 255)  # Red\n",
        "            elif \"TURN\" in rec_text or \"CLIMB\" in rec_text:\n",
        "                color = (0, 165, 255)  # Orange\n",
        "            else:\n",
        "                color = (0, 255, 0)  # Green\n",
        "            \n",
        "            cv2.putText(overlay, rec_text, (20, 40), \n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
        "            \n",
        "            # Additional info if available\n",
        "            if navigation_data and not cached:\n",
        "                info_text = f\"Closest: {navigation_data['closest_obstacle']:.1f}m | \" \\\n",
        "                           f\"Confidence: {navigation_data['confidence']:.1%} | \" \\\n",
        "                           f\"FPS: {navigation_data['fps']:.1f}\"\n",
        "                cv2.putText(overlay, info_text, (20, 70),\n",
        "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
        "            \n",
        "            # Add directional indicators\n",
        "            center_x, center_y = w // 2, h // 2\n",
        "            \n",
        "            if \"LEFT\" in self.last_recommendation:\n",
        "                cv2.arrowedLine(overlay, (center_x, center_y), \n",
        "                               (center_x - 100, center_y), color, 5)\n",
        "            elif \"RIGHT\" in self.last_recommendation:\n",
        "                cv2.arrowedLine(overlay, (center_x, center_y), \n",
        "                               (center_x + 100, center_y), color, 5)\n",
        "            elif \"CLIMB\" in self.last_recommendation:\n",
        "                cv2.arrowedLine(overlay, (center_x, center_y), \n",
        "                               (center_x, center_y - 100), color, 5)\n",
        "        \n",
        "        return overlay\n",
        "\n",
        "# Create video processor instance\n",
        "video_processor = DroneVideoProcessor(nav_analyzer, depth_estimator)\n",
        "\n",
        "print(\"ğŸ¥ Video processor initialized!\")\n",
        "print(\"   - Processing every 5th frame for performance\")\n",
        "print(\"   - Real-time navigation overlay enabled\")\n",
        "print(\"   - FPS tracking enabled\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ’¾ Step 13: Save and Export Calibration\n",
        "\n",
        "Save calibration settings and model performance data for drone deployment:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_calibration_data(results_summary: List[Dict], \n",
        "                         calibration_params: Dict,\n",
        "                         model_performance: Dict):\n",
        "    \"\"\"\n",
        "    Save calibration data and model performance metrics\n",
        "    \"\"\"\n",
        "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "    \n",
        "    calibration_data = {\n",
        "        'timestamp': timestamp,\n",
        "        'calibration_parameters': calibration_params,\n",
        "        'model_performance': model_performance,\n",
        "        'test_results': results_summary,\n",
        "        'system_info': {\n",
        "            'device': depth_estimator.device,\n",
        "            'models_available': list(depth_estimator.models.keys()),\n",
        "            'current_model': depth_estimator.current_model\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    # Save JSON file\n",
        "    output_file = f\"calibration_data/drone_calibration_{timestamp}.json\"\n",
        "    with open(output_file, 'w') as f:\n",
        "        json.dump(calibration_data, f, indent=2)\n",
        "    \n",
        "    print(f\"ğŸ’¾ Calibration data saved to: {output_file}\")\n",
        "    \n",
        "    # Create summary report\n",
        "    report = f\"\"\"\n",
        "    # Drone Navigation Calibration Report\n",
        "    \n",
        "    Generated: {timestamp}\n",
        "    \n",
        "    ## System Configuration\n",
        "    - Device: {calibration_data['system_info']['device']}\n",
        "    - Current Model: {calibration_data['system_info']['current_model']}\n",
        "    - Available Models: {', '.join(calibration_data['system_info']['models_available'])}\n",
        "    \n",
        "    ## Calibration Parameters\n",
        "    - Min Distance: {calibration_params['min_distance']}m\n",
        "    - Max Distance: {calibration_params['max_distance']}m\n",
        "    - Danger Threshold: {calibration_params['danger_threshold']}m\n",
        "    - Warning Threshold: {calibration_params['warning_threshold']}m\n",
        "    - Safe Threshold: {calibration_params['safe_threshold']}m\n",
        "    \n",
        "    ## Performance Metrics\n",
        "    - Average Processing Time: {model_performance['avg_processing_time']:.3f}s\n",
        "    - Average FPS: {model_performance['avg_fps']:.1f}\n",
        "    - Success Rate: {model_performance['success_rate']:.1%}\n",
        "    \n",
        "    ## Test Scenarios Summary\n",
        "    Total Scenarios Tested: {len(results_summary)}\n",
        "    \"\"\"\n",
        "    \n",
        "    # Save report\n",
        "    report_file = f\"calibration_data/drone_calibration_report_{timestamp}.md\"\n",
        "    with open(report_file, 'w') as f:\n",
        "        f.write(report)\n",
        "    \n",
        "    print(f\"ğŸ“„ Calibration report saved to: {report_file}\")\n",
        "    \n",
        "    return calibration_data\n",
        "\n",
        "# Calculate performance metrics\n",
        "if 'all_results' in locals() and all_results:\n",
        "    model_performance = {\n",
        "        'avg_processing_time': np.mean([r['processing_time'] for r in all_results]),\n",
        "        'avg_fps': 1.0 / np.mean([r['processing_time'] for r in all_results]),\n",
        "        'success_rate': len(all_results) / len(os.listdir(\"drone_test_images\"))\n",
        "    }\n",
        "    \n",
        "    calibration_params = {\n",
        "        'min_distance': 0.5,\n",
        "        'max_distance': 10.0,\n",
        "        'danger_threshold': 1.5,\n",
        "        'warning_threshold': 3.0,\n",
        "        'safe_threshold': 5.0\n",
        "    }\n",
        "    \n",
        "    # Save calibration\n",
        "    calibration_data = save_calibration_data(all_results, calibration_params, model_performance)\n",
        "else:\n",
        "    print(\"âš ï¸ No test results available. Run batch processing first to generate calibration data.\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸš€ Step 14: Drone Integration Guide\n",
        "\n",
        "Here's how to integrate this system with your drone:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example drone integration class\n",
        "class DroneNavigationController:\n",
        "    \"\"\"\n",
        "    Example integration for drone flight controller\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, video_processor, calibration_data=None):\n",
        "        self.video_processor = video_processor\n",
        "        self.calibration = calibration_data or {}\n",
        "        self.emergency_stop_enabled = True\n",
        "        self.max_speed = 5.0  # m/s\n",
        "        self.turn_rate = 30  # degrees/s\n",
        "        \n",
        "    def process_navigation_command(self, frame: np.ndarray) -> Dict:\n",
        "        \"\"\"\n",
        "        Process frame and return drone control commands\n",
        "        \n",
        "        Args:\n",
        "            frame: Current camera frame\n",
        "            \n",
        "        Returns:\n",
        "            control_commands: Dictionary with drone control parameters\n",
        "        \"\"\"\n",
        "        # Process frame\n",
        "        processed_frame, nav_data = self.video_processor.process_frame(frame)\n",
        "        \n",
        "        if not nav_data:\n",
        "            return self._get_default_commands()\n",
        "        \n",
        "        recommendation = nav_data['recommendation']\n",
        "        closest_obstacle = nav_data['closest_obstacle']\n",
        "        confidence = nav_data['confidence']\n",
        "        \n",
        "        # Generate control commands based on recommendation\n",
        "        commands = {\n",
        "            'timestamp': time.time(),\n",
        "            'raw_recommendation': recommendation,\n",
        "            'confidence': confidence\n",
        "        }\n",
        "        \n",
        "        # Emergency stop\n",
        "        if recommendation == \"EMERGENCY_STOP\" and self.emergency_stop_enabled:\n",
        "            commands.update({\n",
        "                'action': 'STOP',\n",
        "                'forward_speed': 0,\n",
        "                'lateral_speed': 0,\n",
        "                'vertical_speed': 0,\n",
        "                'yaw_rate': 0,\n",
        "                'emergency': True\n",
        "            })\n",
        "        \n",
        "        # Turn commands\n",
        "        elif recommendation == \"TURN_LEFT\":\n",
        "            speed_factor = min(1.0, closest_obstacle / 3.0)  # Slow down near obstacles\n",
        "            commands.update({\n",
        "                'action': 'TURN_LEFT',\n",
        "                'forward_speed': self.max_speed * speed_factor * 0.3,\n",
        "                'lateral_speed': -self.max_speed * speed_factor * 0.5,\n",
        "                'vertical_speed': 0,\n",
        "                'yaw_rate': -self.turn_rate,\n",
        "                'emergency': False\n",
        "            })\n",
        "        \n",
        "        elif recommendation == \"TURN_RIGHT\":\n",
        "            speed_factor = min(1.0, closest_obstacle / 3.0)\n",
        "            commands.update({\n",
        "                'action': 'TURN_RIGHT',\n",
        "                'forward_speed': self.max_speed * speed_factor * 0.3,\n",
        "                'lateral_speed': self.max_speed * speed_factor * 0.5,\n",
        "                'vertical_speed': 0,\n",
        "                'yaw_rate': self.turn_rate,\n",
        "                'emergency': False\n",
        "            })\n",
        "        \n",
        "        # Climb\n",
        "        elif recommendation == \"CLIMB\":\n",
        "            commands.update({\n",
        "                'action': 'CLIMB',\n",
        "                'forward_speed': 0,\n",
        "                'lateral_speed': 0,\n",
        "                'vertical_speed': self.max_speed * 0.5,\n",
        "                'yaw_rate': 0,\n",
        "                'emergency': False\n",
        "            })\n",
        "        \n",
        "        # Continue forward\n",
        "        elif recommendation == \"CONTINUE_FORWARD\":\n",
        "            speed_factor = min(1.0, (closest_obstacle - 1.5) / 3.5)  # Speed based on distance\n",
        "            commands.update({\n",
        "                'action': 'FORWARD',\n",
        "                'forward_speed': self.max_speed * speed_factor,\n",
        "                'lateral_speed': 0,\n",
        "                'vertical_speed': 0,\n",
        "                'yaw_rate': 0,\n",
        "                'emergency': False\n",
        "            })\n",
        "        \n",
        "        # Hover\n",
        "        else:\n",
        "            commands.update({\n",
        "                'action': 'HOVER',\n",
        "                'forward_speed': 0,\n",
        "                'lateral_speed': 0,\n",
        "                'vertical_speed': 0,\n",
        "                'yaw_rate': 0,\n",
        "                'emergency': False\n",
        "            })\n",
        "        \n",
        "        # Add safety limits\n",
        "        commands = self._apply_safety_limits(commands)\n",
        "        \n",
        "        return commands\n",
        "    \n",
        "    def _get_default_commands(self) -> Dict:\n",
        "        \"\"\"Get default hover commands\"\"\"\n",
        "        return {\n",
        "            'action': 'HOVER',\n",
        "            'forward_speed': 0,\n",
        "            'lateral_speed': 0,\n",
        "            'vertical_speed': 0,\n",
        "            'yaw_rate': 0,\n",
        "            'emergency': False,\n",
        "            'timestamp': time.time()\n",
        "        }\n",
        "    \n",
        "    def _apply_safety_limits(self, commands: Dict) -> Dict:\n",
        "        \"\"\"Apply safety limits to control commands\"\"\"\n",
        "        # Limit speeds\n",
        "        commands['forward_speed'] = np.clip(commands['forward_speed'], -self.max_speed, self.max_speed)\n",
        "        commands['lateral_speed'] = np.clip(commands['lateral_speed'], -self.max_speed, self.max_speed)\n",
        "        commands['vertical_speed'] = np.clip(commands['vertical_speed'], -self.max_speed * 0.5, self.max_speed * 0.5)\n",
        "        commands['yaw_rate'] = np.clip(commands['yaw_rate'], -self.turn_rate, self.turn_rate)\n",
        "        \n",
        "        return commands\n",
        "\n",
        "# Create drone controller\n",
        "drone_controller = DroneNavigationController(video_processor, \n",
        "                                           calibration_data if 'calibration_data' in locals() else None)\n",
        "\n",
        "print(\"ğŸš Drone Navigation Controller initialized!\")\n",
        "print(\"   - Emergency stop: ENABLED\")\n",
        "print(\"   - Max speed: 5.0 m/s\")\n",
        "print(\"   - Turn rate: 30 deg/s\")\n",
        "print(\"\\nâš¡ Ready for integration with flight controller!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ¯ Summary and Next Steps\n",
        "\n",
        "Congratulations! You've built a complete drone obstacle avoidance system using Hugging Face's DepthEstimator. \n",
        "\n",
        "### ğŸ”§ What We've Built:\n",
        "1. **Depth Estimation Pipeline** - Multiple models for depth prediction\n",
        "2. **Distance Calibration** - Convert depth to real-world distances\n",
        "3. **Safety Zone Analysis** - Color-coded danger/warning/safe zones\n",
        "4. **Navigation Recommendations** - Real-time flight path suggestions\n",
        "5. **Batch Processing** - Test multiple scenarios\n",
        "6. **Interactive Interface** - Gradio UI for testing\n",
        "7. **Video Processing** - Real-time frame analysis\n",
        "8. **Drone Integration** - Example flight controller integration\n",
        "\n",
        "### ğŸ“ˆ Performance Metrics:\n",
        "- Processing speed suitable for real-time operation\n",
        "- Multiple safety thresholds for different flight scenarios\n",
        "- Confidence scoring for navigation decisions\n",
        "- FPS tracking for performance monitoring\n",
        "\n",
        "### ğŸš€ Next Steps:\n",
        "1. **Hardware Integration**:\n",
        "   - Connect to your drone's flight controller (PX4, ArduPilot, etc.)\n",
        "   - Integrate with onboard camera system\n",
        "   - Test with actual drone hardware\n",
        "\n",
        "2. **Performance Optimization**:\n",
        "   - Use TensorRT or ONNX for faster inference\n",
        "   - Implement edge computing solutions\n",
        "   - Optimize for specific hardware (Jetson, Raspberry Pi)\n",
        "\n",
        "3. **Advanced Features**:\n",
        "   - Add object detection for specific obstacle types\n",
        "   - Implement SLAM for mapping\n",
        "   - Add GPS integration for waypoint navigation\n",
        "   - Multi-camera support for 360Â° awareness\n",
        "\n",
        "4. **Safety Enhancements**:\n",
        "   - Add redundancy systems\n",
        "   - Implement fail-safe modes\n",
        "   - Add weather condition detection\n",
        "   - Create flight logs for analysis\n",
        "\n",
        "### ğŸ“š Resources:\n",
        "- [Hugging Face Depth Estimation Models](https://huggingface.co/models?pipeline_tag=depth-estimation)\n",
        "- [PX4 Autopilot Documentation](https://px4.io/)\n",
        "- [ArduPilot Documentation](https://ardupilot.org/)\n",
        "- [MAVLink Protocol](https://mavlink.io/)\n",
        "\n",
        "### âš ï¸ Safety Disclaimer:\n",
        "Always test thoroughly in controlled environments before deploying on actual drones. Follow local regulations and safety guidelines for drone operations.\n",
        "\n",
        "Happy Flying! ğŸšâœ¨\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "04f2006b801c49ac994e14dda9613ca0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8984019841d43e59ec046c07805225b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_acde8da87f6347e88042c6ff4a08af4b",
            "value": "preprocessor_config.json:â€‡100%"
          }
        },
        "06863808e7714f038907bf857c9937e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "081665bb69f24fedbce98adb5e59c65c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08e8d78ff45e4564a10280b25258b12c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ae9dc063b244eceac97088c09b0d083": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f1d8bd738e446198e9ec380f61fabbf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11d653070a46429f8aa8f84ff3f7ce6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15f21e82ace04d8386924e33701fb740": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "165318b513894fd88016977bc15edcd4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "184dea3b16bb463aa996c5b5f08fa962": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b485f9a4228741028bc7f08f7e86d4ff",
              "IPY_MODEL_82948517d8cb4e6c9dd1f98db87813a9",
              "IPY_MODEL_7bb37fe3c71c4e189aa330ec0045bc9e"
            ],
            "layout": "IPY_MODEL_ec486de22aaa4c87a285ce338ebec300"
          }
        },
        "1d9f1cc83dfb4eb29620b4e656e52e04": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1dcf88e1788b4319abc804a67a67e04b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d9f1cc83dfb4eb29620b4e656e52e04",
            "max": 489563460,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b7124c220a4c46d2a5a13b405efc0914",
            "value": 489563460
          }
        },
        "1f9bf51e898a485a9be5ad273fb1e6e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1fae395ee4924a738363d858be7e5040": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d516f2b7ae2f4bb9b59bbe7c7353a39a",
            "max": 9876,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a7f064a16ded422e965aec4bf5f70510",
            "value": 9876
          }
        },
        "2914471209cc4f9f86fabf325d3e941f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bbe7229509a4d7c83391cb1e3bb57c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31881d7e817d427d8c25affe202012d5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34a09449fa00495e9472d7cf468131d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37468c9dfd434ffaa5eb9b6c74c35ef5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3aa9d63babb24a23b129791081e2dc02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eacc0671253d4c4c95d99d14cd067457",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_11d653070a46429f8aa8f84ff3f7ce6d",
            "value": "â€‡490M/490Mâ€‡[00:11&lt;00:00,â€‡145MB/s]"
          }
        },
        "3fb13a5fa2e74deb9b18fecb812778ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "421a3ef395244f6e8c6775f4aed5ff8f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43bbd9018f114218b095f0550cca5af8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4d75f185a19e4a76a8e0b612175df267": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7983306679404064b424a8458d236bd5",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_96b4f6c3dbb14af3ae7f972e2be983b1",
            "value": "model.safetensors:â€‡100%"
          }
        },
        "537ce407d1cb4b4abf5813cedc64ffe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56928812992e404882ae75ee22a7d9ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_421a3ef395244f6e8c6775f4aed5ff8f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e05f6d86a38540d38af5c8753723b901",
            "value": "â€‡382/382â€‡[00:00&lt;00:00,â€‡5.56kB/s]"
          }
        },
        "574455c9fb5c436c87666dabe57b3cd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ae9dc063b244eceac97088c09b0d083",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_081665bb69f24fedbce98adb5e59c65c",
            "value": "â€‡942/942â€‡[00:00&lt;00:00,â€‡54.5kB/s]"
          }
        },
        "59c36bb463fc4c36b2b6945aa1537139": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e645327a046f40399be038b5c8f78a10",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_dca180df0ad446daa137ed50ab55f6d9",
            "value": "â€‡285/285â€‡[00:00&lt;00:00,â€‡16.9kB/s]"
          }
        },
        "5c3202bd5f5c44f0bbe679c8f4b353f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93f87716bc434f1bb2bbaf28422e21e3",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1f9bf51e898a485a9be5ad273fb1e6e9",
            "value": "â€‡9.88k/9.88kâ€‡[00:00&lt;00:00,â€‡227kB/s]"
          }
        },
        "604f04c826a8484689f031aeb9554c63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62bd425afada400784bd251861f06e6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bbe7229509a4d7c83391cb1e3bb57c7",
            "max": 382,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e50b733e06494497b13deb1b9106cb19",
            "value": 382
          }
        },
        "688dcbd233e04215a29dfa4b3f4c3566": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15f21e82ace04d8386924e33701fb740",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8cd9526fdaec4fa38e2348f3c4b07eb9",
            "value": "config.json:â€‡100%"
          }
        },
        "699e44e794034e7b9f0ef44e500ff357": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a9429c425924d29b0ee5508c7b49542": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f62dc2f459c422d859fd2edede94a9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4fd5eed6fcd42cea96901e708cdf80f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f85a5370cf134241995ac5ea49728c05",
            "value": "â€‡1.37G/1.37Gâ€‡[00:42&lt;00:00,â€‡63.9MB/s]"
          }
        },
        "6fcb74276ca8486680c84c600f1ac072": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71c7bde17c0e4655bccb5bc193a6c924": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7983306679404064b424a8458d236bd5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bb37fe3c71c4e189aa330ec0045bc9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08e8d78ff45e4564a10280b25258b12c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_fe49b5bb84624a1f95b73e61a5f3763a",
            "value": "â€‡490M/490Mâ€‡[00:10&lt;00:00,â€‡142MB/s]"
          }
        },
        "7fed554f46af4745b15054546fbe925f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dde089dad6ac4a349ca28bda914cc13c",
              "IPY_MODEL_62bd425afada400784bd251861f06e6b",
              "IPY_MODEL_56928812992e404882ae75ee22a7d9ab"
            ],
            "layout": "IPY_MODEL_3fb13a5fa2e74deb9b18fecb812778ca"
          }
        },
        "82948517d8cb4e6c9dd1f98db87813a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e71ce4d8444f49ee970a870c29a14f59",
            "max": 489648389,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_43bbd9018f114218b095f0550cca5af8",
            "value": 489648389
          }
        },
        "8cd9526fdaec4fa38e2348f3c4b07eb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93f87716bc434f1bb2bbaf28422e21e3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96b4f6c3dbb14af3ae7f972e2be983b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96f28cb517eb4bc698c6a943e11af948": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d3bcf3259744ec1b9ad96ab90e9362f",
              "IPY_MODEL_1dcf88e1788b4319abc804a67a67e04b",
              "IPY_MODEL_3aa9d63babb24a23b129791081e2dc02"
            ],
            "layout": "IPY_MODEL_ae4bb369ce91426283ee58c65b5a6aa4"
          }
        },
        "9d3bcf3259744ec1b9ad96ab90e9362f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f19c124e65db483ba37311dad819402e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_537ce407d1cb4b4abf5813cedc64ffe1",
            "value": "model.safetensors:â€‡100%"
          }
        },
        "a1b226390fc240b0b179f5341afc7f45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a9429c425924d29b0ee5508c7b49542",
            "max": 942,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_06863808e7714f038907bf857c9937e4",
            "value": 942
          }
        },
        "a7f064a16ded422e965aec4bf5f70510": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a7f5976634274c879f1d3d9071d436dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_04f2006b801c49ac994e14dda9613ca0",
              "IPY_MODEL_d394aa18a2d345acac71af8da5f298a1",
              "IPY_MODEL_59c36bb463fc4c36b2b6945aa1537139"
            ],
            "layout": "IPY_MODEL_165318b513894fd88016977bc15edcd4"
          }
        },
        "a852776517b84ae9bbd501d75625862a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e55634abc4694f35b38621f3c844a821",
              "IPY_MODEL_1fae395ee4924a738363d858be7e5040",
              "IPY_MODEL_5c3202bd5f5c44f0bbe679c8f4b353f1"
            ],
            "layout": "IPY_MODEL_eabfb58a7718403db6aa809a4753bacb"
          }
        },
        "acde8da87f6347e88042c6ff4a08af4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae4bb369ce91426283ee58c65b5a6aa4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b485f9a4228741028bc7f08f7e86d4ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fcb74276ca8486680c84c600f1ac072",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_699e44e794034e7b9f0ef44e500ff357",
            "value": "pytorch_model.bin:â€‡100%"
          }
        },
        "b4be1c7f8cbc4bf5a910e35765671153": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_688dcbd233e04215a29dfa4b3f4c3566",
              "IPY_MODEL_a1b226390fc240b0b179f5341afc7f45",
              "IPY_MODEL_574455c9fb5c436c87666dabe57b3cd6"
            ],
            "layout": "IPY_MODEL_0f1d8bd738e446198e9ec380f61fabbf"
          }
        },
        "b577cd0777064530afa15bf425373d56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4d75f185a19e4a76a8e0b612175df267",
              "IPY_MODEL_d5b092dc74234aa799dfaabd606024e2",
              "IPY_MODEL_6f62dc2f459c422d859fd2edede94a9a"
            ],
            "layout": "IPY_MODEL_2914471209cc4f9f86fabf325d3e941f"
          }
        },
        "b7124c220a4c46d2a5a13b405efc0914": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d394aa18a2d345acac71af8da5f298a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfdff290eb124222ad1f775f4dffadbf",
            "max": 285,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f020b85b11074428ba1af568b0795cc9",
            "value": 285
          }
        },
        "d516f2b7ae2f4bb9b59bbe7c7353a39a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5b092dc74234aa799dfaabd606024e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31881d7e817d427d8c25affe202012d5",
            "max": 1367456044,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_71c7bde17c0e4655bccb5bc193a6c924",
            "value": 1367456044
          }
        },
        "d8984019841d43e59ec046c07805225b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dca180df0ad446daa137ed50ab55f6d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dde089dad6ac4a349ca28bda914cc13c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa14f721551d4860b7e0b7974714c477",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_604f04c826a8484689f031aeb9554c63",
            "value": "preprocessor_config.json:â€‡100%"
          }
        },
        "dfdff290eb124222ad1f775f4dffadbf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e05f6d86a38540d38af5c8753723b901": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4fd5eed6fcd42cea96901e708cdf80f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e50b733e06494497b13deb1b9106cb19": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e55634abc4694f35b38621f3c844a821": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37468c9dfd434ffaa5eb9b6c74c35ef5",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_34a09449fa00495e9472d7cf468131d2",
            "value": "config.json:â€‡100%"
          }
        },
        "e645327a046f40399be038b5c8f78a10": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e71ce4d8444f49ee970a870c29a14f59": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eabfb58a7718403db6aa809a4753bacb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eacc0671253d4c4c95d99d14cd067457": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec486de22aaa4c87a285ce338ebec300": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f020b85b11074428ba1af568b0795cc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f19c124e65db483ba37311dad819402e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f85a5370cf134241995ac5ea49728c05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa14f721551d4860b7e0b7974714c477": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe49b5bb84624a1f95b73e61a5f3763a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
