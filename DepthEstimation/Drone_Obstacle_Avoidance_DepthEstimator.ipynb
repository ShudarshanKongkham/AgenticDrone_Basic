{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShudarshanKongkham/AgenticDrone_Basic/blob/main/Drone_Obstacle_Avoidance_DepthEstimator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# üöÅ Drone Obstacle Avoidance using Hugging Face DepthEstimator\n",
        "\n",
        "This notebook demonstrates how to build a drone obstacle avoidance system using the **DepthEstimator** from Hugging Face Transformers. We'll develop and calibrate functions step-by-step to understand the surrounding environment for safe drone navigation.\n",
        "\n",
        "<div style=\"text-align: center;\">\n",
        "  <figure style=\"display: inline-block;\">\n",
        "    <img src=\"https://github.com/huggingface/transformers/raw/main/docs/source/en/imgs/depth-estimation-output.png\" alt=\"Depth Estimation for Obstacle Avoidance\" width = 900>\n",
        "    <figcaption style=\"text-align: center;\">Depth Estimation for Drone Obstacle Avoidance</figcaption>\n",
        "  </figure>\n",
        "</div>\n",
        "\n",
        "## üéØ **Objectives:**\n",
        "- Build a step-by-step obstacle avoidance system using Hugging Face transformers\n",
        "- Calibrate depth estimation functions for drone navigation\n",
        "- Create safety zones and navigation recommendations\n",
        "- Develop real-time processing capabilities\n",
        "- Test and validate the system before drone integration\n",
        "\n",
        "## üîß **Key Features:**\n",
        "- **Multiple Models**: Test different depth estimation models from Hugging Face\n",
        "- **Obstacle Detection**: Identify and classify obstacles by distance\n",
        "- **Safety Zones**: Create danger/warning/safe navigation zones\n",
        "- **Flight Path Planning**: Suggest safe navigation directions\n",
        "- **Calibration Tools**: Fine-tune parameters for your specific drone setup\n",
        "- **Real-time Processing**: Optimize for live video feed processing\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üì¶ Step 1: Install Dependencies and Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "%pip install transformers torch torchvision pillow opencv-python matplotlib numpy gradio plotly\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import warnings\n",
        "from typing import Tuple, Dict, List\n",
        "import time\n",
        "import json\n",
        "\n",
        "# Transformers and models\n",
        "from transformers import pipeline, DPTImageProcessor, DPTForDepthEstimation\n",
        "from transformers import AutoImageProcessor, AutoModelForDepthEstimation\n",
        "\n",
        "# Visualization\n",
        "import gradio as gr\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Create directories\n",
        "import os\n",
        "os.makedirs(\"drone_test_images\", exist_ok=True)\n",
        "os.makedirs(\"obstacle_analysis\", exist_ok=True)\n",
        "os.makedirs(\"calibration_data\", exist_ok=True)\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "print(\"‚úÖ All dependencies imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ü§ñ Step 2: Initialize Depth Estimation Models\n",
        "\n",
        "We'll test multiple depth estimation models from Hugging Face to find the best one for drone navigation:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DroneDepthEstimator:\n",
        "    \"\"\"\n",
        "    A class to handle multiple depth estimation models for drone obstacle avoidance\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.models = {}\n",
        "        self.current_model = None\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        print(f\"üîß Using device: {self.device}\")\n",
        "        \n",
        "    def load_model(self, model_name: str, model_id: str):\n",
        "        \"\"\"Load a depth estimation model\"\"\"\n",
        "        try:\n",
        "            print(f\"üì• Loading {model_name}...\")\n",
        "            \n",
        "            if \"dpt\" in model_id.lower():\n",
        "                # DPT models\n",
        "                processor = DPTImageProcessor.from_pretrained(model_id)\n",
        "                model = DPTForDepthEstimation.from_pretrained(model_id)\n",
        "            else:\n",
        "                # Other models\n",
        "                processor = AutoImageProcessor.from_pretrained(model_id)\n",
        "                model = AutoModelForDepthEstimation.from_pretrained(model_id)\n",
        "            \n",
        "            model.to(self.device)\n",
        "            model.eval()\n",
        "            \n",
        "            self.models[model_name] = {\n",
        "                'processor': processor,\n",
        "                'model': model,\n",
        "                'model_id': model_id\n",
        "            }\n",
        "            \n",
        "            print(f\"‚úÖ {model_name} loaded successfully!\")\n",
        "            return True\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Failed to load {model_name}: {str(e)}\")\n",
        "            return False\n",
        "    \n",
        "    def set_current_model(self, model_name: str):\n",
        "        \"\"\"Set the current active model\"\"\"\n",
        "        if model_name in self.models:\n",
        "            self.current_model = model_name\n",
        "            print(f\"üéØ Current model set to: {model_name}\")\n",
        "        else:\n",
        "            print(f\"‚ùå Model {model_name} not found!\")\n",
        "    \n",
        "    def list_available_models(self):\n",
        "        \"\"\"List all loaded models\"\"\"\n",
        "        print(\"üìã Available models:\")\n",
        "        for name, info in self.models.items():\n",
        "            status = \"üéØ ACTIVE\" if name == self.current_model else \"‚ö™ INACTIVE\"\n",
        "            print(f\"  - {name} ({info['model_id']}) {status}\")\n",
        "\n",
        "# Initialize the depth estimator\n",
        "depth_estimator = DroneDepthEstimator()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load multiple depth estimation models for comparison\n",
        "models_to_load = [\n",
        "    (\"DPT-Large\", \"Intel/dpt-large\"),\n",
        "    (\"DPT-Hybrid\", \"Intel/dpt-hybrid-midas\"),\n",
        "    (\"MiDaS\", \"Intel/midas-v2-1-small-256\"),\n",
        "]\n",
        "\n",
        "print(\"üöÄ Loading depth estimation models for drone navigation...\\n\")\n",
        "\n",
        "for model_name, model_id in models_to_load:\n",
        "    success = depth_estimator.load_model(model_name, model_id)\n",
        "    if success and depth_estimator.current_model is None:\n",
        "        depth_estimator.set_current_model(model_name)\n",
        "    print()\n",
        "\n",
        "print(\"üéâ Model loading complete!\")\n",
        "depth_estimator.list_available_models()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üß† Step 3: Core Depth Processing Functions\n",
        "\n",
        "These functions will form the foundation of our drone obstacle avoidance system:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_depth(image: np.ndarray, model_name: str = None) -> Tuple[np.ndarray, Dict]:\n",
        "    \"\"\"\n",
        "    Predict depth map from image using specified model\n",
        "    \n",
        "    Args:\n",
        "        image: Input RGB image (numpy array)\n",
        "        model_name: Name of model to use (if None, uses current model)\n",
        "        \n",
        "    Returns:\n",
        "        depth_map: Depth map as numpy array\n",
        "        metadata: Processing metadata and statistics\n",
        "    \"\"\"\n",
        "    if model_name and model_name in depth_estimator.models:\n",
        "        model_info = depth_estimator.models[model_name]\n",
        "    elif depth_estimator.current_model:\n",
        "        model_info = depth_estimator.models[depth_estimator.current_model]\n",
        "        model_name = depth_estimator.current_model\n",
        "    else:\n",
        "        raise ValueError(\"No model available for depth prediction!\")\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    # Convert numpy array to PIL Image\n",
        "    if isinstance(image, np.ndarray):\n",
        "        if image.shape[2] == 3:  # RGB\n",
        "            pil_image = Image.fromarray(image)\n",
        "        else:\n",
        "            pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    else:\n",
        "        pil_image = image\n",
        "    \n",
        "    # Process image\n",
        "    processor = model_info['processor']\n",
        "    model = model_info['model']\n",
        "    \n",
        "    inputs = processor(images=pil_image, return_tensors=\"pt\").to(depth_estimator.device)\n",
        "    \n",
        "    # Predict depth\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        predicted_depth = outputs.predicted_depth\n",
        "    \n",
        "    # Convert to numpy and normalize\n",
        "    depth_map = predicted_depth.squeeze().cpu().numpy()\n",
        "    \n",
        "    processing_time = time.time() - start_time\n",
        "    \n",
        "    metadata = {\n",
        "        'model_used': model_name,\n",
        "        'processing_time': processing_time,\n",
        "        'min_depth': float(depth_map.min()),\n",
        "        'max_depth': float(depth_map.max()),\n",
        "        'mean_depth': float(depth_map.mean()),\n",
        "        'image_shape': image.shape,\n",
        "        'depth_shape': depth_map.shape\n",
        "    }\n",
        "    \n",
        "    return depth_map, metadata\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calibrate_depth_to_distance(depth_map: np.ndarray, \n",
        "                               min_distance: float = 0.5, \n",
        "                               max_distance: float = 10.0) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Calibrate relative depth values to real-world distances (meters)\n",
        "    \n",
        "    Args:\n",
        "        depth_map: Raw depth map from model\n",
        "        min_distance: Minimum real-world distance in meters\n",
        "        max_distance: Maximum real-world distance in meters\n",
        "        \n",
        "    Returns:\n",
        "        distance_map: Calibrated distance map in meters\n",
        "    \"\"\"\n",
        "    # Invert depth if needed (some models output inverse depth)\n",
        "    if depth_map.min() < 0:\n",
        "        depth_map = -depth_map\n",
        "    \n",
        "    # Normalize to 0-1 range\n",
        "    depth_normalized = (depth_map - depth_map.min()) / (depth_map.max() - depth_map.min())\n",
        "    \n",
        "    # Map to distance range (inverse relationship: closer objects = smaller depth values)\n",
        "    # For many models, smaller values represent closer objects\n",
        "    distance_map = min_distance + (1 - depth_normalized) * (max_distance - min_distance)\n",
        "    \n",
        "    return distance_map\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üö® Step 4: Obstacle Detection and Safety Zones\n",
        "\n",
        "Critical functions for drone safety and navigation:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DroneNavigationAnalyzer:\n",
        "    \"\"\"\n",
        "    Analyze depth maps for drone navigation and obstacle avoidance\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, \n",
        "                 danger_distance: float = 1.5,\n",
        "                 warning_distance: float = 3.0,\n",
        "                 safe_distance: float = 5.0):\n",
        "        \"\"\"\n",
        "        Initialize navigation analyzer with safety thresholds\n",
        "        \n",
        "        Args:\n",
        "            danger_distance: Distance threshold for danger zone (meters)\n",
        "            warning_distance: Distance threshold for warning zone (meters)\n",
        "            safe_distance: Distance threshold for safe zone (meters)\n",
        "        \"\"\"\n",
        "        self.danger_distance = danger_distance\n",
        "        self.warning_distance = warning_distance\n",
        "        self.safe_distance = safe_distance\n",
        "        \n",
        "    def create_safety_zones(self, distance_map: np.ndarray) -> Tuple[np.ndarray, Dict]:\n",
        "        \"\"\"\n",
        "        Create color-coded safety zones for navigation\n",
        "        \n",
        "        Args:\n",
        "            distance_map: Distance map in meters\n",
        "            \n",
        "        Returns:\n",
        "            safety_visualization: RGB image with color-coded zones\n",
        "            zone_statistics: Statistics for each zone\n",
        "        \"\"\"\n",
        "        h, w = distance_map.shape\n",
        "        safety_zones = np.zeros((h, w, 3), dtype=np.uint8)\n",
        "        \n",
        "        # Define zone masks\n",
        "        danger_mask = distance_map < self.danger_distance\n",
        "        warning_mask = (distance_map >= self.danger_distance) & (distance_map < self.warning_distance)\n",
        "        caution_mask = (distance_map >= self.warning_distance) & (distance_map < self.safe_distance)\n",
        "        safe_mask = distance_map >= self.safe_distance\n",
        "        \n",
        "        # Color-code zones (BGR format)\n",
        "        safety_zones[danger_mask] = [0, 0, 255]      # Red - DANGER\n",
        "        safety_zones[warning_mask] = [0, 165, 255]   # Orange - WARNING\n",
        "        safety_zones[caution_mask] = [0, 255, 255]   # Yellow - CAUTION\n",
        "        safety_zones[safe_mask] = [0, 255, 0]        # Green - SAFE\n",
        "        \n",
        "        # Calculate statistics\n",
        "        total_pixels = h * w\n",
        "        zone_stats = {\n",
        "            'danger_pixels': np.sum(danger_mask),\n",
        "            'warning_pixels': np.sum(warning_mask),\n",
        "            'caution_pixels': np.sum(caution_mask),\n",
        "            'safe_pixels': np.sum(safe_mask),\n",
        "            'danger_percentage': (np.sum(danger_mask) / total_pixels) * 100,\n",
        "            'warning_percentage': (np.sum(warning_mask) / total_pixels) * 100,\n",
        "            'caution_percentage': (np.sum(caution_mask) / total_pixels) * 100,\n",
        "            'safe_percentage': (np.sum(safe_mask) / total_pixels) * 100,\n",
        "            'closest_obstacle': float(distance_map.min()),\n",
        "            'average_distance': float(distance_map.mean())\n",
        "        }\n",
        "        \n",
        "        return safety_zones, zone_stats\n",
        "        \n",
        "    def analyze_flight_path(self, distance_map: np.ndarray) -> Dict:\n",
        "        \"\"\"\n",
        "        Analyze the image for safe flight directions\n",
        "        \n",
        "        Args:\n",
        "            distance_map: Distance map in meters\n",
        "            \n",
        "        Returns:\n",
        "            flight_analysis: Recommended flight directions and safety assessment\n",
        "        \"\"\"\n",
        "        h, w = distance_map.shape\n",
        "        \n",
        "        # Divide image into sectors for directional analysis\n",
        "        center_h, center_w = h // 2, w // 2\n",
        "        \n",
        "        # Define sectors\n",
        "        sectors = {\n",
        "            'forward': distance_map[center_h-h//4:center_h+h//4, center_w-w//4:center_w+w//4],\n",
        "            'left': distance_map[:, :w//3],\n",
        "            'right': distance_map[:, 2*w//3:],\n",
        "            'up': distance_map[:h//3, :],\n",
        "            'down': distance_map[2*h//3:, :],\n",
        "            'forward_left': distance_map[center_h-h//4:center_h+h//4, :w//2],\n",
        "            'forward_right': distance_map[center_h-h//4:center_h+h//4, w//2:]\n",
        "        }\n",
        "        \n",
        "        # Analyze each sector\n",
        "        analysis = {}\n",
        "        for direction, sector in sectors.items():\n",
        "            min_dist = float(sector.min())\n",
        "            mean_dist = float(sector.mean())\n",
        "            \n",
        "            # Determine safety level\n",
        "            if min_dist < self.danger_distance:\n",
        "                safety_level = \"DANGER\"\n",
        "                recommendation = \"AVOID\"\n",
        "            elif min_dist < self.warning_distance:\n",
        "                safety_level = \"WARNING\"\n",
        "                recommendation = \"CAUTION\"\n",
        "            elif min_dist < self.safe_distance:\n",
        "                safety_level = \"CAUTION\"\n",
        "                recommendation = \"PROCEED_CAREFULLY\"\n",
        "            else:\n",
        "                safety_level = \"SAFE\"\n",
        "                recommendation = \"CLEAR\"\n",
        "            \n",
        "            analysis[direction] = {\n",
        "                'min_distance': min_dist,\n",
        "                'mean_distance': mean_dist,\n",
        "                'safety_level': safety_level,\n",
        "                'recommendation': recommendation,\n",
        "                'safe_percentage': (np.sum(sector >= self.safe_distance) / sector.size) * 100\n",
        "            }\n",
        "        \n",
        "        # Overall flight recommendation\n",
        "        forward_safety = analysis['forward']['safety_level']\n",
        "        closest_obstacle = float(distance_map.min())\n",
        "        \n",
        "        if closest_obstacle < self.danger_distance:\n",
        "            overall_recommendation = \"EMERGENCY_STOP\"\n",
        "        elif forward_safety == \"SAFE\":\n",
        "            overall_recommendation = \"CONTINUE_FORWARD\"\n",
        "        elif analysis['left']['safety_level'] == \"SAFE\":\n",
        "            overall_recommendation = \"TURN_LEFT\"\n",
        "        elif analysis['right']['safety_level'] == \"SAFE\":\n",
        "            overall_recommendation = \"TURN_RIGHT\"\n",
        "        elif analysis['up']['safety_level'] == \"SAFE\":\n",
        "            overall_recommendation = \"CLIMB\"\n",
        "        else:\n",
        "            overall_recommendation = \"HOVER_AND_REASSESS\"\n",
        "        \n",
        "        analysis['overall'] = {\n",
        "            'recommendation': overall_recommendation,\n",
        "            'closest_obstacle': closest_obstacle,\n",
        "            'confidence': self._calculate_confidence(analysis)\n",
        "        }\n",
        "        \n",
        "        return analysis\n",
        "    \n",
        "    def _calculate_confidence(self, analysis: Dict) -> float:\n",
        "        \"\"\"Calculate confidence score for navigation recommendations\"\"\"\n",
        "        # Simple confidence calculation based on distance margins\n",
        "        min_distances = [data['min_distance'] for data in analysis.values() if isinstance(data, dict)]\n",
        "        if not min_distances:\n",
        "            return 0.5\n",
        "        \n",
        "        avg_min_distance = np.mean(min_distances)\n",
        "        \n",
        "        if avg_min_distance >= self.safe_distance:\n",
        "            return 0.9\n",
        "        elif avg_min_distance >= self.warning_distance:\n",
        "            return 0.7\n",
        "        elif avg_min_distance >= self.danger_distance:\n",
        "            return 0.4\n",
        "        else:\n",
        "            return 0.2\n",
        "\n",
        "# Initialize navigation analyzer\n",
        "nav_analyzer = DroneNavigationAnalyzer()\n",
        "print(\"üß≠ Navigation analyzer initialized with default safety thresholds\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üé® Step 5: Visualization Functions\n",
        "\n",
        "Create comprehensive visualizations for understanding the environment:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_comprehensive_visualization(image: np.ndarray, \n",
        "                                     distance_map: np.ndarray, \n",
        "                                     safety_zones: np.ndarray,\n",
        "                                     flight_analysis: Dict,\n",
        "                                     zone_stats: Dict) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Create a comprehensive visualization for drone navigation\n",
        "    \n",
        "    Args:\n",
        "        image: Original RGB image\n",
        "        distance_map: Distance map in meters\n",
        "        safety_zones: Color-coded safety zones\n",
        "        flight_analysis: Flight path analysis results\n",
        "        zone_stats: Zone statistics\n",
        "        \n",
        "    Returns:\n",
        "        visualization: Combined visualization image\n",
        "    \"\"\"\n",
        "    h, w = image.shape[:2]\n",
        "    \n",
        "    # Create a larger canvas for multiple views\n",
        "    canvas_height = h * 2 + 100  # Extra space for text\n",
        "    canvas_width = w * 2 + 100\n",
        "    canvas = np.zeros((canvas_height, canvas_width, 3), dtype=np.uint8)\n",
        "    \n",
        "    # 1. Original image (top-left)\n",
        "    canvas[50:50+h, 50:50+w] = image\n",
        "    \n",
        "    # 2. Distance heatmap (top-right)\n",
        "    distance_normalized = cv2.normalize(distance_map, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
        "    distance_colored = cv2.applyColorMap(distance_normalized, cv2.COLORMAP_VIRIDIS)\n",
        "    canvas[50:50+h, 50+w+50:50+w+50+w] = distance_colored\n",
        "    \n",
        "    # 3. Safety zones (bottom-left)\n",
        "    canvas[50+h+50:50+h+50+h, 50:50+w] = safety_zones\n",
        "    \n",
        "    # 4. Combined overlay (bottom-right)\n",
        "    overlay = cv2.addWeighted(image, 0.6, safety_zones, 0.4, 0)\n",
        "    canvas[50+h+50:50+h+50+h, 50+w+50:50+w+50+w] = overlay\n",
        "    \n",
        "    # Add labels\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    font_scale = 0.8\n",
        "    color = (255, 255, 255)\n",
        "    thickness = 2\n",
        "    \n",
        "    cv2.putText(canvas, \"Original Image\", (50, 30), font, font_scale, color, thickness)\n",
        "    cv2.putText(canvas, \"Distance Map\", (50+w+50, 30), font, font_scale, color, thickness)\n",
        "    cv2.putText(canvas, \"Safety Zones\", (50, 50+h+30), font, font_scale, color, thickness)\n",
        "    cv2.putText(canvas, \"Navigation Overlay\", (50+w+50, 50+h+30), font, font_scale, color, thickness)\n",
        "    \n",
        "    # Add navigation recommendation\n",
        "    recommendation = flight_analysis['overall']['recommendation']\n",
        "    confidence = flight_analysis['overall']['confidence']\n",
        "    closest_dist = flight_analysis['overall']['closest_obstacle']\n",
        "    \n",
        "    # Color-code recommendation\n",
        "    if recommendation == \"EMERGENCY_STOP\":\n",
        "        rec_color = (0, 0, 255)  # Red\n",
        "    elif recommendation in [\"TURN_LEFT\", \"TURN_RIGHT\", \"CLIMB\"]:\n",
        "        rec_color = (0, 165, 255)  # Orange\n",
        "    elif recommendation == \"CONTINUE_FORWARD\":\n",
        "        rec_color = (0, 255, 0)  # Green\n",
        "    else:\n",
        "        rec_color = (0, 255, 255)  # Yellow\n",
        "    \n",
        "    # Add recommendation text\n",
        "    rec_text = f\"RECOMMENDATION: {recommendation.replace('_', ' ')}\"\n",
        "    cv2.putText(canvas, rec_text, (50, canvas_height - 60), font, 0.7, rec_color, 2)\n",
        "    \n",
        "    conf_text = f\"Confidence: {confidence:.1%} | Closest: {closest_dist:.1f}m\"\n",
        "    cv2.putText(canvas, conf_text, (50, canvas_height - 30), font, 0.6, (255, 255, 255), 2)\n",
        "    \n",
        "    return canvas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_directional_analysis_plot(flight_analysis: Dict):\n",
        "    \"\"\"\n",
        "    Create a plotly radar chart showing directional safety analysis\n",
        "    \"\"\"\n",
        "    directions = ['forward', 'left', 'right', 'up', 'down', 'forward_left', 'forward_right']\n",
        "    \n",
        "    # Extract data for radar chart\n",
        "    min_distances = [flight_analysis[d]['min_distance'] for d in directions]\n",
        "    safety_percentages = [flight_analysis[d]['safe_percentage'] for d in directions]\n",
        "    \n",
        "    # Create radar chart\n",
        "    fig = go.Figure()\n",
        "    \n",
        "    fig.add_trace(go.Scatterpolar(\n",
        "        r=min_distances,\n",
        "        theta=directions,\n",
        "        fill='toself',\n",
        "        name='Min Distance (m)',\n",
        "        line_color='blue'\n",
        "    ))\n",
        "    \n",
        "    fig.add_trace(go.Scatterpolar(\n",
        "        r=[d/20 for d in safety_percentages],  # Normalize to similar scale\n",
        "        theta=directions,\n",
        "        fill='toself',\n",
        "        name='Safety % (scaled)',\n",
        "        line_color='green',\n",
        "        opacity=0.6\n",
        "    ))\n",
        "    \n",
        "    fig.update_layout(\n",
        "        polar=dict(\n",
        "            radialaxis=dict(\n",
        "                visible=True,\n",
        "                range=[0, max(min_distances) * 1.1]\n",
        "            )),\n",
        "        showlegend=True,\n",
        "        title=\"üß≠ Directional Safety Analysis\"\n",
        "    )\n",
        "    \n",
        "    return fig\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üîß Step 6: Complete Processing Pipeline\n",
        "\n",
        "Combine all functions into a comprehensive processing pipeline:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_drone_navigation(image: np.ndarray, \n",
        "                           model_name: str = None,\n",
        "                           min_distance: float = 0.5,\n",
        "                           max_distance: float = 10.0,\n",
        "                           danger_threshold: float = 1.5,\n",
        "                           warning_threshold: float = 3.0,\n",
        "                           safe_threshold: float = 5.0) -> Dict:\n",
        "    \"\"\"\n",
        "    Complete pipeline for drone navigation analysis\n",
        "    \n",
        "    Args:\n",
        "        image: Input RGB image\n",
        "        model_name: Depth estimation model to use\n",
        "        min_distance: Minimum calibration distance (meters)\n",
        "        max_distance: Maximum calibration distance (meters)\n",
        "        danger_threshold: Danger zone threshold (meters)\n",
        "        warning_threshold: Warning zone threshold (meters)\n",
        "        safe_threshold: Safe zone threshold (meters)\n",
        "        \n",
        "    Returns:\n",
        "        results: Complete analysis results with visualizations\n",
        "    \"\"\"\n",
        "    start_time = time.time()\n",
        "    \n",
        "    # Step 1: Predict depth\n",
        "    print(\"üîç Predicting depth...\")\n",
        "    depth_map, depth_metadata = predict_depth(image, model_name)\n",
        "    \n",
        "    # Step 2: Calibrate to real-world distances\n",
        "    print(\"üìè Calibrating distances...\")\n",
        "    distance_map = calibrate_depth_to_distance(depth_map, min_distance, max_distance)\n",
        "    \n",
        "    # Step 3: Update navigation analyzer thresholds\n",
        "    nav_analyzer.danger_distance = danger_threshold\n",
        "    nav_analyzer.warning_distance = warning_threshold\n",
        "    nav_analyzer.safe_distance = safe_threshold\n",
        "    \n",
        "    # Step 4: Create safety zones\n",
        "    print(\"üö® Analyzing safety zones...\")\n",
        "    safety_zones, zone_stats = nav_analyzer.create_safety_zones(distance_map)\n",
        "    \n",
        "    # Step 5: Analyze flight paths\n",
        "    print(\"üß≠ Analyzing flight paths...\")\n",
        "    flight_analysis = nav_analyzer.analyze_flight_path(distance_map)\n",
        "    \n",
        "    # Step 6: Create visualizations\n",
        "    print(\"üé® Creating visualizations...\")\n",
        "    comprehensive_viz = create_comprehensive_visualization(\n",
        "        image, distance_map, safety_zones, flight_analysis, zone_stats\n",
        "    )\n",
        "    \n",
        "    # Create directional analysis plot\n",
        "    directional_plot = create_directional_analysis_plot(flight_analysis)\n",
        "    \n",
        "    total_time = time.time() - start_time\n",
        "    \n",
        "    # Compile results\n",
        "    results = {\n",
        "        'processing_time': total_time,\n",
        "        'depth_metadata': depth_metadata,\n",
        "        'distance_map': distance_map,\n",
        "        'safety_zones': safety_zones,\n",
        "        'zone_statistics': zone_stats,\n",
        "        'flight_analysis': flight_analysis,\n",
        "        'comprehensive_visualization': comprehensive_viz,\n",
        "        'directional_plot': directional_plot,\n",
        "        'calibration_params': {\n",
        "            'min_distance': min_distance,\n",
        "            'max_distance': max_distance,\n",
        "            'danger_threshold': danger_threshold,\n",
        "            'warning_threshold': warning_threshold,\n",
        "            'safe_threshold': safe_threshold\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    print(f\"‚úÖ Analysis complete in {total_time:.2f} seconds\")\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üì• Step 7: Download Test Images\n",
        "\n",
        "Download test images that simulate different drone navigation scenarios:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download test images for different drone scenarios\n",
        "test_images = [\n",
        "    # Outdoor scenarios\n",
        "    (\"forest_path\", \"https://images.unsplash.com/photo-1441974231531-c6227db76b6e\"),\n",
        "    (\"urban_street\", \"https://images.unsplash.com/photo-1506905925346-21bda4d32df4\"),\n",
        "    (\"mountain_view\", \"https://images.unsplash.com/photo-1464822759844-d150baef493e\"),\n",
        "    \n",
        "    # Indoor scenarios  \n",
        "    (\"corridor\", \"https://images.unsplash.com/photo-1586023492125-27b2c045efd7\"),\n",
        "    (\"warehouse\", \"https://images.unsplash.com/photo-1553062407-98eeb64c6a62\"),\n",
        "    \n",
        "    # Complex scenarios\n",
        "    (\"cluttered_room\", \"https://images.unsplash.com/photo-1555041469-a586c61ea9bc\"),\n",
        "]\n",
        "\n",
        "print(\"üì• Downloading test images...\")\n",
        "import urllib.request\n",
        "\n",
        "for name, url in test_images:\n",
        "    try:\n",
        "        filename = f\"drone_test_images/{name}.jpg\"\n",
        "        urllib.request.urlretrieve(url, filename)\n",
        "        print(f\"‚úÖ Downloaded: {name}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to download {name}: {str(e)}\")\n",
        "\n",
        "print(\"\\nüéâ Test images ready for drone navigation analysis!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
