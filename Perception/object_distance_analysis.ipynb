{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Object Distance Analysis\n",
        "## Combining Object Detection with Depth Estimation\n",
        "\n",
        "This notebook demonstrates how to combine YOLO object detection with depth estimation to identify objects and calculate their distances from the camera.\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### Import Required Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "import torch\n",
        "from transformers import DPTImageProcessor, DPTForDepthEstimation\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "import time\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Tuple, Dict\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### Define Data Structures\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class DetectedObject:\n",
        "    \"\"\"Data class for storing detected object information with distance\"\"\"\n",
        "    class_name: str\n",
        "    confidence: float\n",
        "    bbox: Tuple[int, int, int, int]  # x1, y1, x2, y2\n",
        "    center_point: Tuple[int, int]\n",
        "    distance: float  # in meters\n",
        "    min_distance: float  # minimum distance in bounding box\n",
        "    max_distance: float  # maximum distance in bounding box\n",
        "    avg_distance: float  # average distance in bounding box\n",
        "    \n",
        "    def __str__(self):\n",
        "        return f\"{self.class_name} (conf: {self.confidence:.2f}, dist: {self.distance:.2f}m)\"\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### Object Distance Analyzer Class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ObjectDistanceAnalyzer:\n",
        "    \"\"\"Combines YOLO object detection with depth estimation for distance analysis\"\"\"\n",
        "    \n",
        "    def __init__(self, yolo_model=\"yolo11n.pt\", depth_model=\"Intel/dpt-large\"):\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        print(f\"üîß Using device: {self.device}\")\n",
        "        \n",
        "        # Load YOLO model\n",
        "        print(\"üì• Loading YOLO object detection model...\")\n",
        "        self.yolo_model = YOLO(yolo_model)\n",
        "        print(\"‚úÖ YOLO model loaded successfully!\")\n",
        "        \n",
        "        # Load depth estimation model\n",
        "        print(\"üì• Loading depth estimation model...\")\n",
        "        try:\n",
        "            self.depth_processor = DPTImageProcessor.from_pretrained(depth_model)\n",
        "            self.depth_model = DPTForDepthEstimation.from_pretrained(depth_model)\n",
        "            self.depth_model.to(self.device)\n",
        "            self.depth_model.eval()\n",
        "            print(\"‚úÖ Depth model loaded successfully!\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Failed to load depth model: {str(e)}\")\n",
        "            print(\"üîÑ Trying fallback model...\")\n",
        "            self.depth_processor = DPTImageProcessor.from_pretrained(\"Intel/dpt-hybrid-midas\")\n",
        "            self.depth_model = DPTForDepthEstimation.from_pretrained(\"Intel/dpt-hybrid-midas\")\n",
        "            self.depth_model.to(self.device)\n",
        "            self.depth_model.eval()\n",
        "            print(\"‚úÖ Fallback depth model loaded successfully!\")\n",
        "    \n",
        "    def predict_depth(self, image):\n",
        "        \"\"\"Predict depth map from image\"\"\"\n",
        "        try:\n",
        "            # Convert to PIL Image if needed\n",
        "            if isinstance(image, np.ndarray):\n",
        "                pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "            else:\n",
        "                pil_image = image\n",
        "            \n",
        "            # Process image\n",
        "            inputs = self.depth_processor(images=pil_image, return_tensors=\"pt\").to(self.device)\n",
        "            \n",
        "            # Predict depth\n",
        "            with torch.no_grad():\n",
        "                outputs = self.depth_model(**inputs)\n",
        "                predicted_depth = outputs.predicted_depth\n",
        "            \n",
        "            # Convert to numpy and normalize\n",
        "            depth_map = predicted_depth.squeeze().cpu().numpy()\n",
        "            \n",
        "            return depth_map\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error in depth prediction: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def calibrate_depth_to_distance(self, depth_map, min_distance=0.3, max_distance=10.0):\n",
        "        \"\"\"Convert relative depth values to real-world distances\"\"\"\n",
        "        if depth_map.min() < 0:\n",
        "            depth_map = -depth_map\n",
        "        \n",
        "        # Normalize to 0-1 range\n",
        "        depth_normalized = (depth_map - depth_map.min()) / (depth_map.max() - depth_map.min())\n",
        "        \n",
        "        # Map to distance range (closer objects have higher depth values)\n",
        "        distance_map = min_distance + (1 - depth_normalized) * (max_distance - min_distance)\n",
        "        \n",
        "        return distance_map\n",
        "    \n",
        "    def detect_objects(self, image, confidence_threshold=0.5):\n",
        "        \"\"\"Detect objects using YOLO\"\"\"\n",
        "        results = self.yolo_model(image, conf=confidence_threshold)\n",
        "        return results[0] if results else None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Additional methods for the ObjectDistanceAnalyzer class\n",
        "\n",
        "def analyze_image(self, image, confidence_threshold=0.5):\n",
        "    \"\"\"Analyze image for objects and their distances\"\"\"\n",
        "    # Detect objects\n",
        "    detection_results = self.detect_objects(image, confidence_threshold)\n",
        "    \n",
        "    # Predict depth\n",
        "    depth_map = self.predict_depth(image)\n",
        "    if depth_map is None:\n",
        "        return [], None\n",
        "    \n",
        "    # Convert depth to distance\n",
        "    distance_map = self.calibrate_depth_to_distance(depth_map)\n",
        "    \n",
        "    # Resize distance map to match image dimensions\n",
        "    img_height, img_width = image.shape[:2]\n",
        "    distance_map_resized = cv2.resize(distance_map, (img_width, img_height))\n",
        "    \n",
        "    detected_objects = []\n",
        "    \n",
        "    if detection_results.boxes is not None:\n",
        "        for box in detection_results.boxes:\n",
        "            # Get bounding box coordinates\n",
        "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)\n",
        "            confidence = box.conf[0].cpu().numpy()\n",
        "            class_id = int(box.cls[0].cpu().numpy())\n",
        "            class_name = self.yolo_model.names[class_id]\n",
        "            \n",
        "            # Calculate center point\n",
        "            center_x = (x1 + x2) // 2\n",
        "            center_y = (y1 + y2) // 2\n",
        "            \n",
        "            # Extract distance information from bounding box region\n",
        "            bbox_distances = distance_map_resized[y1:y2, x1:x2]\n",
        "            \n",
        "            if bbox_distances.size > 0:\n",
        "                min_distance = float(np.min(bbox_distances))\n",
        "                max_distance = float(np.max(bbox_distances))\n",
        "                avg_distance = float(np.mean(bbox_distances))\n",
        "                center_distance = float(distance_map_resized[center_y, center_x])\n",
        "            else:\n",
        "                min_distance = max_distance = avg_distance = center_distance = 0.0\n",
        "            \n",
        "            detected_obj = DetectedObject(\n",
        "                class_name=class_name,\n",
        "                confidence=float(confidence),\n",
        "                bbox=(x1, y1, x2, y2),\n",
        "                center_point=(center_x, center_y),\n",
        "                distance=center_distance,\n",
        "                min_distance=min_distance,\n",
        "                max_distance=max_distance,\n",
        "                avg_distance=avg_distance\n",
        "            )\n",
        "            \n",
        "            detected_objects.append(detected_obj)\n",
        "    \n",
        "    return detected_objects, distance_map_resized\n",
        "\n",
        "# Monkey patch the method to the class (for notebook demonstration)\n",
        "ObjectDistanceAnalyzer.analyze_image = analyze_image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization method for the ObjectDistanceAnalyzer class\n",
        "\n",
        "def visualize_results(self, image, detected_objects, distance_map=None):\n",
        "    \"\"\"Visualize detection results with distance information\"\"\"\n",
        "    fig, axes = plt.subplots(1, 3 if distance_map is not None else 2, figsize=(20, 8))\n",
        "    \n",
        "    # Original image with detections\n",
        "    img_with_detections = image.copy()\n",
        "    \n",
        "    for obj in detected_objects:\n",
        "        x1, y1, x2, y2 = obj.bbox\n",
        "        \n",
        "        # Draw bounding box\n",
        "        cv2.rectangle(img_with_detections, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "        \n",
        "        # Prepare label text\n",
        "        label = f\"{obj.class_name} {obj.confidence:.2f}\\n{obj.distance:.2f}m\"\n",
        "        \n",
        "        # Draw label background\n",
        "        label_size = cv2.getTextSize(label.split('\\n')[0], cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]\n",
        "        cv2.rectangle(img_with_detections, (x1, y1-40), (x1 + label_size[0] + 50, y1), (0, 255, 0), -1)\n",
        "        \n",
        "        # Draw label text\n",
        "        cv2.putText(img_with_detections, obj.class_name, (x1+5, y1-25), \n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)\n",
        "        cv2.putText(img_with_detections, f\"{obj.distance:.2f}m\", (x1+5, y1-10), \n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0), 1)\n",
        "        \n",
        "        # Draw center point\n",
        "        cv2.circle(img_with_detections, obj.center_point, 3, (255, 0, 0), -1)\n",
        "    \n",
        "    # Plot 1: Original image with detections\n",
        "    axes[0].imshow(cv2.cvtColor(img_with_detections, cv2.COLOR_BGR2RGB))\n",
        "    axes[0].set_title('Objects with Distance Information')\n",
        "    axes[0].axis('off')\n",
        "    \n",
        "    # Plot 2: Distance map or statistics\n",
        "    if distance_map is not None:\n",
        "        im = axes[1].imshow(distance_map, cmap='jet', vmin=0, vmax=10)\n",
        "        axes[1].set_title('Distance Map (meters)')\n",
        "        axes[1].axis('off')\n",
        "        plt.colorbar(im, ax=axes[1], shrink=0.6)\n",
        "        \n",
        "        # Plot 3: Overlay\n",
        "        axes[2].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB), alpha=0.7)\n",
        "        axes[2].imshow(distance_map, cmap='jet', alpha=0.3, vmin=0, vmax=10)\n",
        "        \n",
        "        # Add bounding boxes to overlay\n",
        "        for obj in detected_objects:\n",
        "            x1, y1, x2, y2 = obj.bbox\n",
        "            rect = Rectangle((x1, y1), x2-x1, y2-y1, linewidth=2, \n",
        "                           edgecolor='white', facecolor='none')\n",
        "            axes[2].add_patch(rect)\n",
        "            axes[2].text(x1, y1-5, f\"{obj.class_name}\\n{obj.distance:.2f}m\", \n",
        "                       color='white', fontsize=8, weight='bold')\n",
        "        \n",
        "        axes[2].set_title('Distance Overlay')\n",
        "        axes[2].axis('off')\n",
        "    else:\n",
        "        # Plot statistics if no distance map\n",
        "        if detected_objects:\n",
        "            distances = [obj.distance for obj in detected_objects]\n",
        "            class_names = [obj.class_name for obj in detected_objects]\n",
        "            \n",
        "            axes[1].bar(range(len(distances)), distances)\n",
        "            axes[1].set_xticks(range(len(distances)))\n",
        "            axes[1].set_xticklabels(class_names, rotation=45)\n",
        "            axes[1].set_ylabel('Distance (meters)')\n",
        "            axes[1].set_title('Object Distances')\n",
        "        else:\n",
        "            axes[1].text(0.5, 0.5, 'No objects detected', \n",
        "                       ha='center', va='center', transform=axes[1].transAxes)\n",
        "            axes[1].set_title('No Detections')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Print detection summary\n",
        "    print(\"\\nüéØ Detection Summary:\")\n",
        "    print(\"-\" * 50)\n",
        "    for i, obj in enumerate(detected_objects, 1):\n",
        "        print(f\"{i}. {obj}\")\n",
        "        print(f\"   üìç Position: {obj.center_point}\")\n",
        "        print(f\"   üìè Distance range: {obj.min_distance:.2f}m - {obj.max_distance:.2f}m (avg: {obj.avg_distance:.2f}m)\")\n",
        "        print()\n",
        "    \n",
        "    if not detected_objects:\n",
        "        print(\"No objects detected in the image.\")\n",
        "\n",
        "# Monkey patch the visualization method\n",
        "ObjectDistanceAnalyzer.visualize_results = visualize_results\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### Initialize the Analyzer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the analyzer\n",
        "analyzer = ObjectDistanceAnalyzer()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### Test with Webcam\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Capture image from webcam\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "if cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if ret:\n",
        "        print(\"üì∏ Image captured from webcam\")\n",
        "        \n",
        "        # Analyze the frame\n",
        "        detected_objects, distance_map = analyzer.analyze_image(frame, confidence_threshold=0.3)\n",
        "        \n",
        "        # Visualize results\n",
        "        analyzer.visualize_results(frame, detected_objects, distance_map)\n",
        "    else:\n",
        "        print(\"‚ùå Failed to capture image from webcam\")\n",
        "else:\n",
        "    print(\"‚ùå Could not open webcam\")\n",
        "\n",
        "cap.release()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### Real-time Analysis Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def real_time_analysis(duration_seconds=30):\n",
        "    \"\"\"Run real-time object distance analysis for specified duration\"\"\"\n",
        "    cap = cv2.VideoCapture(0)\n",
        "    \n",
        "    if not cap.isOpened():\n",
        "        print(\"‚ùå Could not open webcam\")\n",
        "        return\n",
        "    \n",
        "    print(f\"üé• Starting real-time analysis for {duration_seconds} seconds...\")\n",
        "    print(\"Press 'q' to quit early\")\n",
        "    \n",
        "    start_time = time.time()\n",
        "    frame_count = 0\n",
        "    \n",
        "    while time.time() - start_time < duration_seconds:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        \n",
        "        frame_count += 1\n",
        "        \n",
        "        # Analyze every 10th frame to maintain performance\n",
        "        if frame_count % 10 == 0:\n",
        "            detected_objects, _ = analyzer.analyze_image(frame, confidence_threshold=0.5)\n",
        "            \n",
        "            # Draw detections on frame\n",
        "            for obj in detected_objects:\n",
        "                x1, y1, x2, y2 = obj.bbox\n",
        "                \n",
        "                # Draw bounding box\n",
        "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "                \n",
        "                # Draw label\n",
        "                label = f\"{obj.class_name}: {obj.distance:.1f}m\"\n",
        "                cv2.rectangle(frame, (x1, y1-30), (x1 + 200, y1), (0, 255, 0), -1)\n",
        "                cv2.putText(frame, label, (x1+5, y1-10), \n",
        "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
        "        \n",
        "        # Display frame\n",
        "        cv2.imshow('Object Distance Analysis', frame)\n",
        "        \n",
        "        # Check for quit\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "    \n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    print(\"üèÅ Real-time analysis completed\")\n",
        "\n",
        "# Uncomment to run real-time analysis\n",
        "# real_time_analysis(30)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
